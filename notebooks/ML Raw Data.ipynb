{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# time\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ETL\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend import clear_session\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# K-fold\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "models = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 369)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "## Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Slit (X,Y)\n",
    "x_data = df.drop(['ID','TARGET'], axis=1)\n",
    "y_data = df['TARGET'].copy()\n",
    "\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_10            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.722939</td>\n",
       "      <td>0.700387</td>\n",
       "      <td>0.700387</td>\n",
       "      <td>0.534673</td>\n",
       "      <td>0.700387</td>\n",
       "      <td>0.482338</td>\n",
       "      <td>0.690648</td>\n",
       "      <td>00:28:44.911659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.717956</td>\n",
       "      <td>0.720511</td>\n",
       "      <td>0.720511</td>\n",
       "      <td>0.537513</td>\n",
       "      <td>0.720511</td>\n",
       "      <td>0.482410</td>\n",
       "      <td>0.683414</td>\n",
       "      <td>00:28:50.553132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.722231</td>\n",
       "      <td>0.708877</td>\n",
       "      <td>0.708877</td>\n",
       "      <td>0.536129</td>\n",
       "      <td>0.708877</td>\n",
       "      <td>0.484372</td>\n",
       "      <td>0.691660</td>\n",
       "      <td>00:28:18.624045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.722081</td>\n",
       "      <td>0.694201</td>\n",
       "      <td>0.694201</td>\n",
       "      <td>0.533682</td>\n",
       "      <td>0.694201</td>\n",
       "      <td>0.481389</td>\n",
       "      <td>0.691002</td>\n",
       "      <td>00:28:27.111376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.721969</td>\n",
       "      <td>0.704066</td>\n",
       "      <td>0.704066</td>\n",
       "      <td>0.534975</td>\n",
       "      <td>0.704066</td>\n",
       "      <td>0.480523</td>\n",
       "      <td>0.685478</td>\n",
       "      <td>00:28:36.196548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.719687</td>\n",
       "      <td>0.719376</td>\n",
       "      <td>0.719376</td>\n",
       "      <td>0.537386</td>\n",
       "      <td>0.719376</td>\n",
       "      <td>0.482650</td>\n",
       "      <td>0.684294</td>\n",
       "      <td>00:28:29.247570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.721117</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.535823</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.480896</td>\n",
       "      <td>0.684162</td>\n",
       "      <td>00:28:26.677938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.721981</td>\n",
       "      <td>0.668359</td>\n",
       "      <td>0.668359</td>\n",
       "      <td>0.529529</td>\n",
       "      <td>0.668359</td>\n",
       "      <td>0.477697</td>\n",
       "      <td>0.693370</td>\n",
       "      <td>00:28:36.870633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.723040</td>\n",
       "      <td>0.701392</td>\n",
       "      <td>0.701392</td>\n",
       "      <td>0.534368</td>\n",
       "      <td>0.701392</td>\n",
       "      <td>0.479262</td>\n",
       "      <td>0.684252</td>\n",
       "      <td>00:28:35.959235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.718899</td>\n",
       "      <td>0.699793</td>\n",
       "      <td>0.699793</td>\n",
       "      <td>0.534109</td>\n",
       "      <td>0.699793</td>\n",
       "      <td>0.478979</td>\n",
       "      <td>0.684252</td>\n",
       "      <td>00:28:41.292946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.721190</td>\n",
       "      <td>0.702671</td>\n",
       "      <td>0.702671</td>\n",
       "      <td>0.534819</td>\n",
       "      <td>0.702671</td>\n",
       "      <td>0.481052</td>\n",
       "      <td>0.687253</td>\n",
       "      <td>00:28:34.744508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>00:00:09.042620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.722939  0.700387  0.700387   0.534673  0.700387  0.482338   \n",
       "KF_2      0.717956  0.720511  0.720511   0.537513  0.720511  0.482410   \n",
       "KF_3      0.722231  0.708877  0.708877   0.536129  0.708877  0.484372   \n",
       "KF_4      0.722081  0.694201  0.694201   0.533682  0.694201  0.481389   \n",
       "KF_5      0.721969  0.704066  0.704066   0.534975  0.704066  0.480523   \n",
       "KF_6      0.719687  0.719376  0.719376   0.537386  0.719376  0.482650   \n",
       "KF_7      0.721117  0.709751  0.709751   0.535823  0.709751  0.480896   \n",
       "KF_8      0.721981  0.668359  0.668359   0.529529  0.668359  0.477697   \n",
       "KF_9      0.723040  0.701392  0.701392   0.534368  0.701392  0.479262   \n",
       "KF_10     0.718899  0.699793  0.699793   0.534109  0.699793  0.478979   \n",
       "Media     0.721190  0.702671  0.702671   0.534819  0.702671  0.481052   \n",
       "STD       0.001660  0.013972  0.013972   0.002159  0.013972  0.001904   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.690648 00:28:44.911659  \n",
       "KF_2   0.683414 00:28:50.553132  \n",
       "KF_3   0.691660 00:28:18.624045  \n",
       "KF_4   0.691002 00:28:27.111376  \n",
       "KF_5   0.685478 00:28:36.196548  \n",
       "KF_6   0.684294 00:28:29.247570  \n",
       "KF_7   0.684162 00:28:26.677938  \n",
       "KF_8   0.693370 00:28:36.870633  \n",
       "KF_9   0.684252 00:28:35.959235  \n",
       "KF_10  0.684252 00:28:41.292946  \n",
       "Media  0.687253 00:28:34.744508  \n",
       "STD    0.003696 00:00:09.042620  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'SVM(RBF)'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i+'            ', end=\"\\r\")\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = SVC(C=0.1, kernel='rbf', class_weight = 'balanced')\n",
    "    model.fit(x_train, y_train)\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train, model.predict(x_train))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred)\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "    \n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()\n",
    "    \n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_10            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.891688</td>\n",
       "      <td>0.832710</td>\n",
       "      <td>0.832710</td>\n",
       "      <td>0.558441</td>\n",
       "      <td>0.744391</td>\n",
       "      <td>0.558599</td>\n",
       "      <td>0.814941</td>\n",
       "      <td>00:03:26.346158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.888480</td>\n",
       "      <td>0.865366</td>\n",
       "      <td>0.865366</td>\n",
       "      <td>0.565990</td>\n",
       "      <td>0.789432</td>\n",
       "      <td>0.566595</td>\n",
       "      <td>0.809680</td>\n",
       "      <td>00:03:17.345438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.890543</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.841645</td>\n",
       "      <td>0.561938</td>\n",
       "      <td>0.758490</td>\n",
       "      <td>0.564032</td>\n",
       "      <td>0.817548</td>\n",
       "      <td>00:03:17.581789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.891124</td>\n",
       "      <td>0.838652</td>\n",
       "      <td>0.838652</td>\n",
       "      <td>0.563817</td>\n",
       "      <td>0.766864</td>\n",
       "      <td>0.566748</td>\n",
       "      <td>0.818337</td>\n",
       "      <td>00:03:15.761269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.890873</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.820321</td>\n",
       "      <td>0.553727</td>\n",
       "      <td>0.727237</td>\n",
       "      <td>0.550661</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>00:03:16.295998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.890395</td>\n",
       "      <td>0.840443</td>\n",
       "      <td>0.843765</td>\n",
       "      <td>0.560788</td>\n",
       "      <td>0.769023</td>\n",
       "      <td>0.557966</td>\n",
       "      <td>0.804130</td>\n",
       "      <td>00:03:17.157190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.890893</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>0.834360</td>\n",
       "      <td>0.561520</td>\n",
       "      <td>0.765735</td>\n",
       "      <td>0.560967</td>\n",
       "      <td>0.810050</td>\n",
       "      <td>00:03:17.216914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.891211</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>0.823007</td>\n",
       "      <td>0.558584</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.558304</td>\n",
       "      <td>0.813470</td>\n",
       "      <td>00:03:16.991969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.891298</td>\n",
       "      <td>0.828341</td>\n",
       "      <td>0.831674</td>\n",
       "      <td>0.559549</td>\n",
       "      <td>0.757068</td>\n",
       "      <td>0.558224</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>00:03:16.873340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.891196</td>\n",
       "      <td>0.839654</td>\n",
       "      <td>0.839654</td>\n",
       "      <td>0.562006</td>\n",
       "      <td>0.767547</td>\n",
       "      <td>0.561991</td>\n",
       "      <td>0.811341</td>\n",
       "      <td>00:03:16.344796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.890770</td>\n",
       "      <td>0.835785</td>\n",
       "      <td>0.837115</td>\n",
       "      <td>0.560636</td>\n",
       "      <td>0.759260</td>\n",
       "      <td>0.560409</td>\n",
       "      <td>0.811865</td>\n",
       "      <td>00:03:17.791486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>00:00:02.899848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.891688  0.832710  0.832710   0.558441  0.744391  0.558599   \n",
       "KF_2      0.888480  0.865366  0.865366   0.565990  0.789432  0.566595   \n",
       "KF_3      0.890543  0.838323  0.841645   0.561938  0.758490  0.564032   \n",
       "KF_4      0.891124  0.838652  0.838652   0.563817  0.766864  0.566748   \n",
       "KF_5      0.890873  0.816999  0.820321   0.553727  0.727237  0.550661   \n",
       "KF_6      0.890395  0.840443  0.843765   0.560788  0.769023  0.557966   \n",
       "KF_7      0.890893  0.834360  0.834360   0.561520  0.765735  0.560967   \n",
       "KF_8      0.891211  0.823007  0.823007   0.558584  0.746811  0.558304   \n",
       "KF_9      0.891298  0.828341  0.831674   0.559549  0.757068  0.558224   \n",
       "KF_10     0.891196  0.839654  0.839654   0.562006  0.767547  0.561991   \n",
       "Media     0.890770  0.835785  0.837115   0.560636  0.759260  0.560409   \n",
       "STD       0.000842  0.012286  0.011872   0.003180  0.016065  0.004559   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.814941 00:03:26.346158  \n",
       "KF_2   0.809680 00:03:17.345438  \n",
       "KF_3   0.817548 00:03:17.581789  \n",
       "KF_4   0.818337 00:03:15.761269  \n",
       "KF_5   0.809524 00:03:16.295998  \n",
       "KF_6   0.804130 00:03:17.157190  \n",
       "KF_7   0.810050 00:03:17.216914  \n",
       "KF_8   0.813470 00:03:16.991969  \n",
       "KF_9   0.809630 00:03:16.873340  \n",
       "KF_10  0.811341 00:03:16.344796  \n",
       "Media  0.811865 00:03:17.791486  \n",
       "STD    0.004060 00:00:02.899848  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'RF'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i+'            ', end=\"\\r\")\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = RandomForestClassifier(\n",
    "                                   n_estimators = 800,\n",
    "                                   min_samples_leaf = 85,\n",
    "                                   max_features = 0.3,\n",
    "                                   class_weight = 'balanced',\n",
    "                                   n_jobs=-1\n",
    "                                  )\n",
    "    model.fit(x_train, y_train)\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train, model.predict_proba(x_train)[:,1])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred_proba)\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "\n",
    "print()\n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()\n",
    "    \n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_10            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.889943</td>\n",
       "      <td>0.831867</td>\n",
       "      <td>0.835189</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.503254</td>\n",
       "      <td>0.496513</td>\n",
       "      <td>0.960542</td>\n",
       "      <td>00:02:33.951274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.887030</td>\n",
       "      <td>0.866937</td>\n",
       "      <td>0.870260</td>\n",
       "      <td>0.980268</td>\n",
       "      <td>0.501661</td>\n",
       "      <td>0.493247</td>\n",
       "      <td>0.960542</td>\n",
       "      <td>00:02:32.589816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.889116</td>\n",
       "      <td>0.843929</td>\n",
       "      <td>0.843929</td>\n",
       "      <td>0.480197</td>\n",
       "      <td>0.499863</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.960142</td>\n",
       "      <td>00:02:32.272124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.889746</td>\n",
       "      <td>0.843638</td>\n",
       "      <td>0.843638</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>0.489867</td>\n",
       "      <td>0.960274</td>\n",
       "      <td>00:02:32.793471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.889997</td>\n",
       "      <td>0.822948</td>\n",
       "      <td>0.822948</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>0.489867</td>\n",
       "      <td>0.960274</td>\n",
       "      <td>00:02:31.350691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.889041</td>\n",
       "      <td>0.847339</td>\n",
       "      <td>0.847339</td>\n",
       "      <td>0.480197</td>\n",
       "      <td>0.499863</td>\n",
       "      <td>0.489833</td>\n",
       "      <td>0.960142</td>\n",
       "      <td>00:02:31.911194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.890166</td>\n",
       "      <td>0.835590</td>\n",
       "      <td>0.835590</td>\n",
       "      <td>0.813660</td>\n",
       "      <td>0.503254</td>\n",
       "      <td>0.496512</td>\n",
       "      <td>0.960537</td>\n",
       "      <td>00:02:32.176045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.889595</td>\n",
       "      <td>0.828730</td>\n",
       "      <td>0.828730</td>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.501593</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.960405</td>\n",
       "      <td>00:02:31.628107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.889533</td>\n",
       "      <td>0.829546</td>\n",
       "      <td>0.832879</td>\n",
       "      <td>0.980329</td>\n",
       "      <td>0.501667</td>\n",
       "      <td>0.493289</td>\n",
       "      <td>0.960663</td>\n",
       "      <td>00:02:32.479781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.888695</td>\n",
       "      <td>0.847053</td>\n",
       "      <td>0.847053</td>\n",
       "      <td>0.855453</td>\n",
       "      <td>0.504932</td>\n",
       "      <td>0.499867</td>\n",
       "      <td>0.960795</td>\n",
       "      <td>00:02:31.977137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.839758</td>\n",
       "      <td>0.840756</td>\n",
       "      <td>0.709443</td>\n",
       "      <td>0.501595</td>\n",
       "      <td>0.493203</td>\n",
       "      <td>0.960431</td>\n",
       "      <td>00:02:32.312964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>0.200103</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>00:00:00.686223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.889943  0.831867  0.835189   0.813662  0.503254  0.496513   \n",
       "KF_2      0.887030  0.866937  0.870260   0.980268  0.501661  0.493247   \n",
       "KF_3      0.889116  0.843929  0.843929   0.480197  0.499863  0.489833   \n",
       "KF_4      0.889746  0.843638  0.843638   0.480200  0.499932  0.489867   \n",
       "KF_5      0.889997  0.822948  0.822948   0.480200  0.499932  0.489867   \n",
       "KF_6      0.889041  0.847339  0.847339   0.480197  0.499863  0.489833   \n",
       "KF_7      0.890166  0.835590  0.835590   0.813660  0.503254  0.496512   \n",
       "KF_8      0.889595  0.828730  0.828730   0.730263  0.501593  0.493200   \n",
       "KF_9      0.889533  0.829546  0.832879   0.980329  0.501667  0.493289   \n",
       "KF_10     0.888695  0.847053  0.847053   0.855453  0.504932  0.499867   \n",
       "Media     0.889286  0.839758  0.840756   0.709443  0.501595  0.493203   \n",
       "STD       0.000872  0.012124  0.012463   0.200103  0.001679  0.003336   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.960542 00:02:33.951274  \n",
       "KF_2   0.960542 00:02:32.589816  \n",
       "KF_3   0.960142 00:02:32.272124  \n",
       "KF_4   0.960274 00:02:32.793471  \n",
       "KF_5   0.960274 00:02:31.350691  \n",
       "KF_6   0.960142 00:02:31.911194  \n",
       "KF_7   0.960537 00:02:32.176045  \n",
       "KF_8   0.960405 00:02:31.628107  \n",
       "KF_9   0.960663 00:02:32.479781  \n",
       "KF_10  0.960795 00:02:31.977137  \n",
       "Media  0.960431 00:02:32.312964  \n",
       "STD    0.000210 00:00:00.686223  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'XGBoost'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i+'            ', end=\"\\r\")\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = XGBClassifier(\n",
    "                          learning_rate = 0.03,\n",
    "                          n_estimators = 350, \n",
    "                          objective = 'reg:logistic',\n",
    "                          max_depth = 5,\n",
    "                          subsample = 0.75,\n",
    "                          colsample_bytree=0.7\n",
    "                        )\n",
    "    model.fit(x_train, y_train)\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train, model.predict_proba(x_train)[:,1])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred_proba)\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "\n",
    "print()\n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()\n",
    "    \n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_1\n",
      "Train on 97566 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97566/97566 [==============================] - 15s - loss: 0.4599 - acc: 0.7968 - val_loss: 0.4284 - val_acc: 0.8007\n",
      "Epoch 2/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.4012 - acc: 0.8351 - val_loss: 0.4033 - val_acc: 0.8386\n",
      "Epoch 3/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.3635 - acc: 0.8511 - val_loss: 0.4416 - val_acc: 0.8214\n",
      "Epoch 4/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.3427 - acc: 0.8588 - val_loss: 0.4142 - val_acc: 0.8286\n",
      "Epoch 5/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.3256 - acc: 0.8674 - val_loss: 0.3123 - val_acc: 0.8674\n",
      "Epoch 6/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.3139 - acc: 0.8716 - val_loss: 0.3364 - val_acc: 0.8486\n",
      "Epoch 7/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.3042 - acc: 0.8754 - val_loss: 0.4119 - val_acc: 0.8283\n",
      "Epoch 8/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2984 - acc: 0.8789 - val_loss: 0.3627 - val_acc: 0.8490\n",
      "Epoch 9/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2904 - acc: 0.8817 - val_loss: 0.3196 - val_acc: 0.8620\n",
      "Epoch 10/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2848 - acc: 0.8848 - val_loss: 0.3374 - val_acc: 0.8610\n",
      "Epoch 11/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2805 - acc: 0.8875 - val_loss: 0.3219 - val_acc: 0.8528\n",
      "Epoch 12/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2768 - acc: 0.8892 - val_loss: 0.3789 - val_acc: 0.8377\n",
      "Epoch 13/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2730 - acc: 0.8902 - val_loss: 0.4230 - val_acc: 0.8210\n",
      "Epoch 14/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2696 - acc: 0.8919 - val_loss: 0.3019 - val_acc: 0.8645\n",
      "Epoch 15/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2660 - acc: 0.8933 - val_loss: 0.5156 - val_acc: 0.8207\n",
      "Epoch 16/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2626 - acc: 0.8948 - val_loss: 0.3694 - val_acc: 0.8473\n",
      "Epoch 17/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2601 - acc: 0.8959 - val_loss: 0.2994 - val_acc: 0.8663\n",
      "Epoch 18/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2574 - acc: 0.8973 - val_loss: 0.3500 - val_acc: 0.8503\n",
      "Epoch 19/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2556 - acc: 0.8981 - val_loss: 0.3690 - val_acc: 0.8416\n",
      "Epoch 20/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2522 - acc: 0.8991 - val_loss: 0.3208 - val_acc: 0.8628\n",
      "Epoch 21/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2504 - acc: 0.9006 - val_loss: 0.3414 - val_acc: 0.8593\n",
      "Epoch 22/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2492 - acc: 0.9009 - val_loss: 0.3428 - val_acc: 0.8571\n",
      "Epoch 23/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2475 - acc: 0.9018 - val_loss: 0.2995 - val_acc: 0.8629\n",
      "Epoch 24/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2448 - acc: 0.9033 - val_loss: 0.2905 - val_acc: 0.8721\n",
      "Epoch 25/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2434 - acc: 0.9035 - val_loss: 0.3208 - val_acc: 0.8639\n",
      "Epoch 26/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2406 - acc: 0.9047 - val_loss: 0.2853 - val_acc: 0.8750\n",
      "Epoch 27/10000\n",
      "97566/97566 [==============================] - 8s - loss: 0.2394 - acc: 0.9058 - val_loss: 0.3737 - val_acc: 0.8447\n",
      "Epoch 28/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2374 - acc: 0.9060 - val_loss: 0.3089 - val_acc: 0.8722\n",
      "Epoch 29/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2367 - acc: 0.9064 - val_loss: 0.3685 - val_acc: 0.8503\n",
      "Epoch 30/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2355 - acc: 0.9071 - val_loss: 0.3329 - val_acc: 0.8555\n",
      "Epoch 31/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2328 - acc: 0.9082 - val_loss: 0.3093 - val_acc: 0.8707\n",
      "Epoch 32/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2319 - acc: 0.9082 - val_loss: 0.3485 - val_acc: 0.8612\n",
      "Epoch 33/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2307 - acc: 0.9098 - val_loss: 0.3704 - val_acc: 0.8588\n",
      "Epoch 34/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2294 - acc: 0.9097 - val_loss: 0.2939 - val_acc: 0.8712\n",
      "Epoch 35/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2287 - acc: 0.9107 - val_loss: 0.2566 - val_acc: 0.8840\n",
      "Epoch 36/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2273 - acc: 0.9105 - val_loss: 0.2574 - val_acc: 0.8839\n",
      "Epoch 37/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2268 - acc: 0.9112 - val_loss: 0.3679 - val_acc: 0.8588\n",
      "Epoch 38/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2253 - acc: 0.9121 - val_loss: 0.2698 - val_acc: 0.8838\n",
      "Epoch 39/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2237 - acc: 0.9121 - val_loss: 0.3197 - val_acc: 0.8686\n",
      "Epoch 40/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2240 - acc: 0.9128 - val_loss: 0.2531 - val_acc: 0.8910\n",
      "Epoch 41/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2230 - acc: 0.9132 - val_loss: 0.3082 - val_acc: 0.8678\n",
      "Epoch 42/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2210 - acc: 0.9131 - val_loss: 0.3253 - val_acc: 0.8695\n",
      "Epoch 43/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2209 - acc: 0.9132 - val_loss: 0.2947 - val_acc: 0.8752\n",
      "Epoch 44/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2194 - acc: 0.9139 - val_loss: 0.3169 - val_acc: 0.8683\n",
      "Epoch 45/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2191 - acc: 0.9147 - val_loss: 0.3347 - val_acc: 0.8580\n",
      "Epoch 46/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2175 - acc: 0.9152 - val_loss: 0.2960 - val_acc: 0.8721\n",
      "Epoch 47/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2174 - acc: 0.9155 - val_loss: 0.2980 - val_acc: 0.8699\n",
      "Epoch 48/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2171 - acc: 0.9155 - val_loss: 0.3350 - val_acc: 0.8549\n",
      "Epoch 49/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2148 - acc: 0.9168 - val_loss: 0.3460 - val_acc: 0.8636\n",
      "Epoch 50/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2144 - acc: 0.9166 - val_loss: 0.2789 - val_acc: 0.8810\n",
      "Epoch 51/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2145 - acc: 0.9162 - val_loss: 0.2973 - val_acc: 0.8747\n",
      "Epoch 52/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2133 - acc: 0.9175 - val_loss: 0.2872 - val_acc: 0.8773\n",
      "Epoch 53/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2128 - acc: 0.9176 - val_loss: 0.3153 - val_acc: 0.8736\n",
      "Epoch 54/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2129 - acc: 0.9176 - val_loss: 0.3169 - val_acc: 0.8716\n",
      "Epoch 55/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2123 - acc: 0.9177 - val_loss: 0.3542 - val_acc: 0.8587\n",
      "Epoch 56/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2115 - acc: 0.9184 - val_loss: 0.4242 - val_acc: 0.8487\n",
      "Epoch 57/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2110 - acc: 0.9174 - val_loss: 0.2786 - val_acc: 0.8825\n",
      "Epoch 58/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2095 - acc: 0.9186 - val_loss: 0.3893 - val_acc: 0.8582\n",
      "Epoch 59/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2097 - acc: 0.9185 - val_loss: 0.3335 - val_acc: 0.8693\n",
      "Epoch 60/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2088 - acc: 0.9189 - val_loss: 0.3039 - val_acc: 0.8731\n",
      "Epoch 61/10000\n",
      "97566/97566 [==============================] - 6s - loss: 0.2083 - acc: 0.9194 - val_loss: 0.3319 - val_acc: 0.8653\n",
      "96928/97566 [============================>.] - ETA: 0sKF_2\n",
      "Train on 97559 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.4644 - acc: 0.7933 - val_loss: 0.4799 - val_acc: 0.7591\n",
      "Epoch 2/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.4002 - acc: 0.8318 - val_loss: 0.3756 - val_acc: 0.8381\n",
      "Epoch 3/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.3630 - acc: 0.8492 - val_loss: 0.3893 - val_acc: 0.8290\n",
      "Epoch 4/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.3402 - acc: 0.8579 - val_loss: 0.3716 - val_acc: 0.8380\n",
      "Epoch 5/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.3253 - acc: 0.8653 - val_loss: 0.3153 - val_acc: 0.8445\n",
      "Epoch 6/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.3157 - acc: 0.8696 - val_loss: 0.3893 - val_acc: 0.8313\n",
      "Epoch 7/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.3069 - acc: 0.8735 - val_loss: 0.3382 - val_acc: 0.8501\n",
      "Epoch 8/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.3000 - acc: 0.8772 - val_loss: 0.4228 - val_acc: 0.8191\n",
      "Epoch 9/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2943 - acc: 0.8803 - val_loss: 0.3420 - val_acc: 0.8618\n",
      "Epoch 10/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2898 - acc: 0.8819 - val_loss: 0.3259 - val_acc: 0.8622\n",
      "Epoch 11/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2855 - acc: 0.8841 - val_loss: 0.3179 - val_acc: 0.8612\n",
      "Epoch 12/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2811 - acc: 0.8860 - val_loss: 0.3961 - val_acc: 0.8321\n",
      "Epoch 13/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2771 - acc: 0.8879 - val_loss: 0.3633 - val_acc: 0.8544\n",
      "Epoch 14/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2735 - acc: 0.8897 - val_loss: 0.3934 - val_acc: 0.8438\n",
      "Epoch 15/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2706 - acc: 0.8907 - val_loss: 0.3560 - val_acc: 0.8410\n",
      "Epoch 16/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2680 - acc: 0.8920 - val_loss: 0.3186 - val_acc: 0.8649\n",
      "Epoch 17/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2651 - acc: 0.8940 - val_loss: 0.2461 - val_acc: 0.9005\n",
      "Epoch 18/10000\n",
      "97559/97559 [==============================] - 9s - loss: 0.2625 - acc: 0.8946 - val_loss: 0.3175 - val_acc: 0.8544\n",
      "Epoch 19/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2601 - acc: 0.8961 - val_loss: 0.3151 - val_acc: 0.8641\n",
      "Epoch 20/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2579 - acc: 0.8967 - val_loss: 0.3667 - val_acc: 0.8552\n",
      "Epoch 21/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2556 - acc: 0.8974 - val_loss: 0.2844 - val_acc: 0.8812\n",
      "Epoch 22/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2531 - acc: 0.8992 - val_loss: 0.3675 - val_acc: 0.8552\n",
      "Epoch 23/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2509 - acc: 0.8998 - val_loss: 0.4006 - val_acc: 0.8476\n",
      "Epoch 24/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2491 - acc: 0.9010 - val_loss: 0.3483 - val_acc: 0.8584\n",
      "Epoch 25/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2478 - acc: 0.9015 - val_loss: 0.3473 - val_acc: 0.8616\n",
      "Epoch 26/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2460 - acc: 0.9032 - val_loss: 0.3439 - val_acc: 0.8584\n",
      "Epoch 27/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2443 - acc: 0.9046 - val_loss: 0.3903 - val_acc: 0.8327\n",
      "Epoch 28/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2426 - acc: 0.9052 - val_loss: 0.4054 - val_acc: 0.8392\n",
      "Epoch 29/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2409 - acc: 0.9047 - val_loss: 0.3182 - val_acc: 0.8575\n",
      "Epoch 30/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2393 - acc: 0.9060 - val_loss: 0.4198 - val_acc: 0.8432\n",
      "Epoch 31/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2387 - acc: 0.9061 - val_loss: 0.2824 - val_acc: 0.8778\n",
      "Epoch 32/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2362 - acc: 0.9071 - val_loss: 0.2801 - val_acc: 0.8795\n",
      "Epoch 33/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2366 - acc: 0.9080 - val_loss: 0.2913 - val_acc: 0.8775\n",
      "Epoch 34/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2347 - acc: 0.9083 - val_loss: 0.3535 - val_acc: 0.8603\n",
      "Epoch 35/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2333 - acc: 0.9087 - val_loss: 0.3912 - val_acc: 0.8375\n",
      "Epoch 36/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2316 - acc: 0.9093 - val_loss: 0.4700 - val_acc: 0.8390\n",
      "Epoch 37/10000\n",
      "97559/97559 [==============================] - 6s - loss: 0.2309 - acc: 0.9089 - val_loss: 0.3090 - val_acc: 0.8740\n",
      "Epoch 38/10000\n",
      "97559/97559 [==============================] - 7s - loss: 0.2296 - acc: 0.9100 - val_loss: 0.3371 - val_acc: 0.8673\n",
      "96832/97559 [============================>.] - ETA: 0sKF_3\n",
      "Train on 97540 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.4642 - acc: 0.7928 - val_loss: 0.4910 - val_acc: 0.7801\n",
      "Epoch 2/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.3976 - acc: 0.8366 - val_loss: 0.3861 - val_acc: 0.8388\n",
      "Epoch 3/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.3631 - acc: 0.8498 - val_loss: 0.3849 - val_acc: 0.8354\n",
      "Epoch 4/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.3398 - acc: 0.8592 - val_loss: 0.3927 - val_acc: 0.8341\n",
      "Epoch 5/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.3238 - acc: 0.8662 - val_loss: 0.3574 - val_acc: 0.8411\n",
      "Epoch 6/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.3137 - acc: 0.8713 - val_loss: 0.2993 - val_acc: 0.8701\n",
      "Epoch 7/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.3052 - acc: 0.8736 - val_loss: 0.3902 - val_acc: 0.8480\n",
      "Epoch 8/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2988 - acc: 0.8777 - val_loss: 0.2898 - val_acc: 0.8729\n",
      "Epoch 9/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2928 - acc: 0.8810 - val_loss: 0.3349 - val_acc: 0.8565\n",
      "Epoch 10/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2870 - acc: 0.8829 - val_loss: 0.3444 - val_acc: 0.8606\n",
      "Epoch 11/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2827 - acc: 0.8855 - val_loss: 0.4111 - val_acc: 0.8354\n",
      "Epoch 12/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2795 - acc: 0.8865 - val_loss: 0.3851 - val_acc: 0.8324\n",
      "Epoch 13/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2748 - acc: 0.8888 - val_loss: 0.3789 - val_acc: 0.8495\n",
      "Epoch 14/10000\n",
      "97540/97540 [==============================] - 8s - loss: 0.2704 - acc: 0.8909 - val_loss: 0.4033 - val_acc: 0.8364\n",
      "Epoch 15/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2683 - acc: 0.8918 - val_loss: 0.3021 - val_acc: 0.8665\n",
      "Epoch 16/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2640 - acc: 0.8935 - val_loss: 0.3766 - val_acc: 0.8427\n",
      "Epoch 17/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2613 - acc: 0.8947 - val_loss: 0.3186 - val_acc: 0.8596\n",
      "Epoch 18/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2591 - acc: 0.8951 - val_loss: 0.3401 - val_acc: 0.8623\n",
      "Epoch 19/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2553 - acc: 0.8966 - val_loss: 0.4138 - val_acc: 0.8330\n",
      "Epoch 20/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2539 - acc: 0.8973 - val_loss: 0.3493 - val_acc: 0.8462\n",
      "Epoch 21/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2510 - acc: 0.8987 - val_loss: 0.4254 - val_acc: 0.8244\n",
      "Epoch 22/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2487 - acc: 0.8999 - val_loss: 0.3996 - val_acc: 0.8416\n",
      "Epoch 23/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2477 - acc: 0.9005 - val_loss: 0.3849 - val_acc: 0.8466\n",
      "Epoch 24/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97540/97540 [==============================] - 7s - loss: 0.2454 - acc: 0.9015 - val_loss: 0.3227 - val_acc: 0.8680\n",
      "Epoch 25/10000\n",
      "97540/97540 [==============================] - 9s - loss: 0.2432 - acc: 0.9024 - val_loss: 0.2991 - val_acc: 0.8591\n",
      "Epoch 26/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2414 - acc: 0.9036 - val_loss: 0.4195 - val_acc: 0.8335\n",
      "Epoch 27/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2396 - acc: 0.9053 - val_loss: 0.3355 - val_acc: 0.8565\n",
      "Epoch 28/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2382 - acc: 0.9047 - val_loss: 0.2742 - val_acc: 0.8815\n",
      "Epoch 29/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2363 - acc: 0.9057 - val_loss: 0.3758 - val_acc: 0.8560\n",
      "Epoch 30/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2346 - acc: 0.9063 - val_loss: 0.4225 - val_acc: 0.8202\n",
      "Epoch 31/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2339 - acc: 0.9077 - val_loss: 0.3572 - val_acc: 0.8518\n",
      "Epoch 32/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2324 - acc: 0.9080 - val_loss: 0.3139 - val_acc: 0.8620\n",
      "Epoch 33/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2303 - acc: 0.9074 - val_loss: 0.3028 - val_acc: 0.8734\n",
      "Epoch 34/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2278 - acc: 0.9099 - val_loss: 0.3921 - val_acc: 0.8560\n",
      "Epoch 35/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2281 - acc: 0.9100 - val_loss: 0.2839 - val_acc: 0.8737\n",
      "Epoch 36/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2266 - acc: 0.9098 - val_loss: 0.3103 - val_acc: 0.8571\n",
      "Epoch 37/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2250 - acc: 0.9101 - val_loss: 0.3948 - val_acc: 0.8555\n",
      "Epoch 38/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2241 - acc: 0.9111 - val_loss: 0.3269 - val_acc: 0.8637\n",
      "Epoch 39/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2230 - acc: 0.9117 - val_loss: 0.3387 - val_acc: 0.8588\n",
      "Epoch 40/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2224 - acc: 0.9119 - val_loss: 0.3447 - val_acc: 0.8608\n",
      "Epoch 41/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2212 - acc: 0.9122 - val_loss: 0.3836 - val_acc: 0.8521\n",
      "Epoch 42/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2198 - acc: 0.9135 - val_loss: 0.3487 - val_acc: 0.8616\n",
      "Epoch 43/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2192 - acc: 0.9136 - val_loss: 0.3287 - val_acc: 0.8693\n",
      "Epoch 44/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2187 - acc: 0.9141 - val_loss: 0.2956 - val_acc: 0.8759\n",
      "Epoch 45/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2169 - acc: 0.9141 - val_loss: 0.2849 - val_acc: 0.8799\n",
      "Epoch 46/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2163 - acc: 0.9142 - val_loss: 0.3632 - val_acc: 0.8592\n",
      "Epoch 47/10000\n",
      "97540/97540 [==============================] - 7s - loss: 0.2153 - acc: 0.9141 - val_loss: 0.3207 - val_acc: 0.8690\n",
      "Epoch 48/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2146 - acc: 0.9161 - val_loss: 0.3080 - val_acc: 0.8750\n",
      "Epoch 49/10000\n",
      "97540/97540 [==============================] - 6s - loss: 0.2143 - acc: 0.9156 - val_loss: 0.3973 - val_acc: 0.8462\n",
      "97540/97540 [==============================] - 7s     \n",
      "KF_4\n",
      "Train on 97499 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.4690 - acc: 0.7886 - val_loss: 0.4686 - val_acc: 0.7759\n",
      "Epoch 2/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.4027 - acc: 0.8306 - val_loss: 0.4192 - val_acc: 0.8241\n",
      "Epoch 3/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.3670 - acc: 0.8471 - val_loss: 0.3823 - val_acc: 0.8399\n",
      "Epoch 4/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.3472 - acc: 0.8540 - val_loss: 0.3762 - val_acc: 0.8506\n",
      "Epoch 5/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.3320 - acc: 0.8619 - val_loss: 0.3186 - val_acc: 0.8693\n",
      "Epoch 6/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.3210 - acc: 0.8661 - val_loss: 0.3978 - val_acc: 0.8386\n",
      "Epoch 7/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.3123 - acc: 0.8716 - val_loss: 0.3163 - val_acc: 0.8673\n",
      "Epoch 8/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.3038 - acc: 0.8730 - val_loss: 0.4039 - val_acc: 0.8307\n",
      "Epoch 9/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2981 - acc: 0.8764 - val_loss: 0.4309 - val_acc: 0.8316\n",
      "Epoch 10/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2930 - acc: 0.8782 - val_loss: 0.3833 - val_acc: 0.8443\n",
      "Epoch 11/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2885 - acc: 0.8805 - val_loss: 0.3424 - val_acc: 0.8487\n",
      "Epoch 12/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2838 - acc: 0.8828 - val_loss: 0.3525 - val_acc: 0.8416\n",
      "Epoch 13/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2800 - acc: 0.8840 - val_loss: 0.3417 - val_acc: 0.8574\n",
      "Epoch 14/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2758 - acc: 0.8867 - val_loss: 0.4100 - val_acc: 0.8413\n",
      "Epoch 15/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2735 - acc: 0.8876 - val_loss: 0.3496 - val_acc: 0.8555\n",
      "Epoch 16/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2709 - acc: 0.8886 - val_loss: 0.3480 - val_acc: 0.8441\n",
      "Epoch 17/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2669 - acc: 0.8909 - val_loss: 0.3501 - val_acc: 0.8405\n",
      "Epoch 18/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2637 - acc: 0.8917 - val_loss: 0.3749 - val_acc: 0.8489\n",
      "Epoch 19/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2613 - acc: 0.8933 - val_loss: 0.3985 - val_acc: 0.8424\n",
      "Epoch 20/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2584 - acc: 0.8950 - val_loss: 0.3709 - val_acc: 0.8477\n",
      "Epoch 21/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2568 - acc: 0.8953 - val_loss: 0.2994 - val_acc: 0.8605\n",
      "Epoch 22/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2562 - acc: 0.8959 - val_loss: 0.3756 - val_acc: 0.8519\n",
      "Epoch 23/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2539 - acc: 0.8967 - val_loss: 0.3477 - val_acc: 0.8433\n",
      "Epoch 24/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2510 - acc: 0.8978 - val_loss: 0.3172 - val_acc: 0.8636\n",
      "Epoch 25/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2495 - acc: 0.8985 - val_loss: 0.3440 - val_acc: 0.8391\n",
      "Epoch 26/10000\n",
      "97499/97499 [==============================] - 7s - loss: 0.2479 - acc: 0.8996 - val_loss: 0.3130 - val_acc: 0.8612\n",
      "Epoch 27/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2467 - acc: 0.9000 - val_loss: 0.3279 - val_acc: 0.8590\n",
      "Epoch 28/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2437 - acc: 0.9006 - val_loss: 0.3517 - val_acc: 0.8453\n",
      "Epoch 29/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2424 - acc: 0.9016 - val_loss: 0.3452 - val_acc: 0.8646\n",
      "Epoch 30/10000\n",
      "97499/97499 [==============================] - 7s - loss: 0.2409 - acc: 0.9026 - val_loss: 0.2953 - val_acc: 0.8761\n",
      "Epoch 31/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2391 - acc: 0.9038 - val_loss: 0.3103 - val_acc: 0.8675\n",
      "Epoch 32/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2387 - acc: 0.9032 - val_loss: 0.3498 - val_acc: 0.8454\n",
      "Epoch 33/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2368 - acc: 0.9049 - val_loss: 0.3082 - val_acc: 0.8702\n",
      "Epoch 34/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2359 - acc: 0.9049 - val_loss: 0.3490 - val_acc: 0.8524\n",
      "Epoch 35/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2343 - acc: 0.9062 - val_loss: 0.3231 - val_acc: 0.8589\n",
      "Epoch 36/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2340 - acc: 0.9058 - val_loss: 0.3647 - val_acc: 0.8469\n",
      "Epoch 37/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2310 - acc: 0.9074 - val_loss: 0.3370 - val_acc: 0.8632\n",
      "Epoch 38/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2300 - acc: 0.9079 - val_loss: 0.3150 - val_acc: 0.8679\n",
      "Epoch 39/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2289 - acc: 0.9084 - val_loss: 0.3244 - val_acc: 0.8598\n",
      "Epoch 40/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2285 - acc: 0.9093 - val_loss: 0.2750 - val_acc: 0.8821\n",
      "Epoch 41/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2276 - acc: 0.9093 - val_loss: 0.3702 - val_acc: 0.8495\n",
      "Epoch 42/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2263 - acc: 0.9098 - val_loss: 0.2802 - val_acc: 0.8795\n",
      "Epoch 43/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2257 - acc: 0.9095 - val_loss: 0.3022 - val_acc: 0.8662\n",
      "Epoch 44/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2254 - acc: 0.9098 - val_loss: 0.3492 - val_acc: 0.8605\n",
      "Epoch 45/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2237 - acc: 0.9112 - val_loss: 0.3400 - val_acc: 0.8605\n",
      "Epoch 46/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2231 - acc: 0.9110 - val_loss: 0.3745 - val_acc: 0.8468\n",
      "Epoch 47/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2216 - acc: 0.9123 - val_loss: 0.3045 - val_acc: 0.8686\n",
      "Epoch 48/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2218 - acc: 0.9115 - val_loss: 0.3867 - val_acc: 0.8567\n",
      "Epoch 49/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2210 - acc: 0.9120 - val_loss: 0.3538 - val_acc: 0.8622\n",
      "Epoch 50/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2194 - acc: 0.9125 - val_loss: 0.3311 - val_acc: 0.8633\n",
      "Epoch 51/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2190 - acc: 0.9127 - val_loss: 0.3450 - val_acc: 0.8583\n",
      "Epoch 52/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2183 - acc: 0.9141 - val_loss: 0.3969 - val_acc: 0.8508\n",
      "Epoch 53/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2171 - acc: 0.9141 - val_loss: 0.3023 - val_acc: 0.8732\n",
      "Epoch 54/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2162 - acc: 0.9142 - val_loss: 0.3722 - val_acc: 0.8576\n",
      "Epoch 55/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2165 - acc: 0.9145 - val_loss: 0.3027 - val_acc: 0.8782\n",
      "Epoch 56/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2157 - acc: 0.9141 - val_loss: 0.3232 - val_acc: 0.8649\n",
      "Epoch 57/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2143 - acc: 0.9146 - val_loss: 0.2875 - val_acc: 0.8832\n",
      "Epoch 58/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2134 - acc: 0.9158 - val_loss: 0.3580 - val_acc: 0.8543\n",
      "Epoch 59/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2138 - acc: 0.9151 - val_loss: 0.3198 - val_acc: 0.8652\n",
      "Epoch 60/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2123 - acc: 0.9158 - val_loss: 0.3614 - val_acc: 0.8591\n",
      "Epoch 61/10000\n",
      "97499/97499 [==============================] - 6s - loss: 0.2123 - acc: 0.9165 - val_loss: 0.2965 - val_acc: 0.8772\n",
      "97344/97499 [============================>.] - ETA:  - ETA: 0sKF_5\n",
      "Train on 97505 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.4661 - acc: 0.7902 - val_loss: 0.4308 - val_acc: 0.8144\n",
      "Epoch 2/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.3999 - acc: 0.8330 - val_loss: 0.4596 - val_acc: 0.7898\n",
      "Epoch 3/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.3619 - acc: 0.8494 - val_loss: 0.5281 - val_acc: 0.7535\n",
      "Epoch 4/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.3404 - acc: 0.8580 - val_loss: 0.3305 - val_acc: 0.8612\n",
      "Epoch 5/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.3246 - acc: 0.8657 - val_loss: 0.3568 - val_acc: 0.8494\n",
      "Epoch 6/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.3137 - acc: 0.8696 - val_loss: 0.3243 - val_acc: 0.8546\n",
      "Epoch 7/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.3055 - acc: 0.8738 - val_loss: 0.3255 - val_acc: 0.8434\n",
      "Epoch 8/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2985 - acc: 0.8766 - val_loss: 0.3751 - val_acc: 0.8521\n",
      "Epoch 9/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2920 - acc: 0.8804 - val_loss: 0.4067 - val_acc: 0.8450\n",
      "Epoch 10/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2912 - acc: 0.8812 - val_loss: 0.2222 - val_acc: 0.9258\n",
      "Epoch 11/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2846 - acc: 0.8831 - val_loss: 0.3759 - val_acc: 0.8351\n",
      "Epoch 12/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2787 - acc: 0.8859 - val_loss: 0.3724 - val_acc: 0.8260\n",
      "Epoch 13/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2747 - acc: 0.8882 - val_loss: 0.3702 - val_acc: 0.8532\n",
      "Epoch 14/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2717 - acc: 0.8891 - val_loss: 0.5249 - val_acc: 0.7694\n",
      "Epoch 15/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2690 - acc: 0.8906 - val_loss: 0.3958 - val_acc: 0.8435\n",
      "Epoch 16/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2663 - acc: 0.8912 - val_loss: 0.3919 - val_acc: 0.8481\n",
      "Epoch 17/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2630 - acc: 0.8925 - val_loss: 0.3671 - val_acc: 0.8506\n",
      "Epoch 18/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2609 - acc: 0.8939 - val_loss: 0.3468 - val_acc: 0.8666\n",
      "Epoch 19/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2604 - acc: 0.8942 - val_loss: 0.4370 - val_acc: 0.8381\n",
      "Epoch 20/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2565 - acc: 0.8956 - val_loss: 0.4083 - val_acc: 0.8455\n",
      "Epoch 21/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2556 - acc: 0.8955 - val_loss: 0.2974 - val_acc: 0.8716\n",
      "Epoch 22/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2531 - acc: 0.8972 - val_loss: 0.4607 - val_acc: 0.8343\n",
      "Epoch 23/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2514 - acc: 0.8979 - val_loss: 0.4818 - val_acc: 0.8192\n",
      "Epoch 24/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2514 - acc: 0.8979 - val_loss: 0.3547 - val_acc: 0.8329\n",
      "Epoch 25/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2487 - acc: 0.8995 - val_loss: 0.3643 - val_acc: 0.8501\n",
      "Epoch 26/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2482 - acc: 0.8993 - val_loss: 0.3700 - val_acc: 0.8583\n",
      "Epoch 27/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2453 - acc: 0.9012 - val_loss: 0.4972 - val_acc: 0.8152\n",
      "Epoch 28/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2441 - acc: 0.9006 - val_loss: 0.4692 - val_acc: 0.8360\n",
      "Epoch 29/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2429 - acc: 0.9021 - val_loss: 0.3573 - val_acc: 0.8439\n",
      "Epoch 30/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2404 - acc: 0.9034 - val_loss: 0.3529 - val_acc: 0.8567\n",
      "Epoch 31/10000\n",
      "97505/97505 [==============================] - 6s - loss: 0.2404 - acc: 0.9033 - val_loss: 0.5523 - val_acc: 0.7990\n",
      "97505/97505 [==============================] - 7s     \n",
      "KF_6\n",
      "Train on 97312 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97312/97312 [==============================] - 7s - loss: 0.4675 - acc: 0.7896 - val_loss: 0.4755 - val_acc: 0.7700\n",
      "Epoch 2/10000\n",
      "97312/97312 [==============================] - 7s - loss: 0.4074 - acc: 0.8293 - val_loss: 0.4281 - val_acc: 0.8156\n",
      "Epoch 3/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.3720 - acc: 0.8461 - val_loss: 0.3375 - val_acc: 0.8569\n",
      "Epoch 4/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.3485 - acc: 0.8570 - val_loss: 0.4224 - val_acc: 0.8367\n",
      "Epoch 5/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97312/97312 [==============================] - 6s - loss: 0.3306 - acc: 0.8630 - val_loss: 0.3868 - val_acc: 0.8518\n",
      "Epoch 6/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.3201 - acc: 0.8674 - val_loss: 0.3429 - val_acc: 0.8487\n",
      "Epoch 7/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.3099 - acc: 0.8716 - val_loss: 0.3415 - val_acc: 0.8643\n",
      "Epoch 8/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.3013 - acc: 0.8763 - val_loss: 0.3391 - val_acc: 0.8334\n",
      "Epoch 9/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2958 - acc: 0.8790 - val_loss: 0.3086 - val_acc: 0.8652\n",
      "Epoch 10/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2904 - acc: 0.8819 - val_loss: 0.3350 - val_acc: 0.8555\n",
      "Epoch 11/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2843 - acc: 0.8840 - val_loss: 0.3629 - val_acc: 0.8342\n",
      "Epoch 12/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2802 - acc: 0.8856 - val_loss: 0.3950 - val_acc: 0.8357\n",
      "Epoch 13/10000\n",
      "97312/97312 [==============================] - 5s - loss: 0.2774 - acc: 0.8867 - val_loss: 0.2936 - val_acc: 0.8652\n",
      "Epoch 14/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2734 - acc: 0.8897 - val_loss: 0.3800 - val_acc: 0.8511\n",
      "Epoch 15/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2701 - acc: 0.8909 - val_loss: 0.3253 - val_acc: 0.8658\n",
      "Epoch 16/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2672 - acc: 0.8924 - val_loss: 0.2927 - val_acc: 0.8747\n",
      "Epoch 17/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2646 - acc: 0.8936 - val_loss: 0.3270 - val_acc: 0.8556\n",
      "Epoch 18/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2627 - acc: 0.8942 - val_loss: 0.3662 - val_acc: 0.8522\n",
      "Epoch 19/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2603 - acc: 0.8950 - val_loss: 0.2877 - val_acc: 0.8783\n",
      "Epoch 20/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2578 - acc: 0.8975 - val_loss: 0.3991 - val_acc: 0.8333\n",
      "Epoch 21/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2553 - acc: 0.8980 - val_loss: 0.3602 - val_acc: 0.8366\n",
      "Epoch 22/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2545 - acc: 0.8982 - val_loss: 0.2904 - val_acc: 0.8731\n",
      "Epoch 23/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2516 - acc: 0.9001 - val_loss: 0.3156 - val_acc: 0.8557\n",
      "Epoch 24/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2505 - acc: 0.9002 - val_loss: 0.3506 - val_acc: 0.8568\n",
      "Epoch 25/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2479 - acc: 0.9017 - val_loss: 0.3092 - val_acc: 0.8706\n",
      "Epoch 26/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2466 - acc: 0.9019 - val_loss: 0.3047 - val_acc: 0.8733\n",
      "Epoch 27/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2448 - acc: 0.9034 - val_loss: 0.3650 - val_acc: 0.8271\n",
      "Epoch 28/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2445 - acc: 0.9032 - val_loss: 0.2766 - val_acc: 0.8825\n",
      "Epoch 29/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2436 - acc: 0.9036 - val_loss: 0.3464 - val_acc: 0.8560\n",
      "Epoch 30/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2400 - acc: 0.9051 - val_loss: 0.3190 - val_acc: 0.8622\n",
      "Epoch 31/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2398 - acc: 0.9057 - val_loss: 0.3030 - val_acc: 0.8737\n",
      "Epoch 32/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2380 - acc: 0.9062 - val_loss: 0.3246 - val_acc: 0.8641\n",
      "Epoch 33/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2377 - acc: 0.9064 - val_loss: 0.2678 - val_acc: 0.8783\n",
      "Epoch 34/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2364 - acc: 0.9067 - val_loss: 0.3192 - val_acc: 0.8603\n",
      "Epoch 35/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2349 - acc: 0.9078 - val_loss: 0.3436 - val_acc: 0.8653\n",
      "Epoch 36/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2334 - acc: 0.9077 - val_loss: 0.4689 - val_acc: 0.8298\n",
      "Epoch 37/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2325 - acc: 0.9091 - val_loss: 0.3881 - val_acc: 0.8551\n",
      "Epoch 38/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2317 - acc: 0.9090 - val_loss: 0.2865 - val_acc: 0.8788\n",
      "Epoch 39/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2308 - acc: 0.9097 - val_loss: 0.3460 - val_acc: 0.8532\n",
      "Epoch 40/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2296 - acc: 0.9100 - val_loss: 0.4068 - val_acc: 0.8438\n",
      "Epoch 41/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2285 - acc: 0.9114 - val_loss: 0.3288 - val_acc: 0.8689\n",
      "Epoch 42/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2275 - acc: 0.9111 - val_loss: 0.3353 - val_acc: 0.8648\n",
      "Epoch 43/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2264 - acc: 0.9117 - val_loss: 0.3402 - val_acc: 0.8601\n",
      "Epoch 44/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2258 - acc: 0.9121 - val_loss: 0.3605 - val_acc: 0.8507\n",
      "Epoch 45/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2253 - acc: 0.9122 - val_loss: 0.3424 - val_acc: 0.8647\n",
      "Epoch 46/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2242 - acc: 0.9127 - val_loss: 0.2720 - val_acc: 0.8827\n",
      "Epoch 47/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2244 - acc: 0.9121 - val_loss: 0.2911 - val_acc: 0.8764\n",
      "Epoch 48/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2228 - acc: 0.9131 - val_loss: 0.3674 - val_acc: 0.8568\n",
      "Epoch 49/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2217 - acc: 0.9142 - val_loss: 0.2983 - val_acc: 0.8742\n",
      "Epoch 50/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2222 - acc: 0.9140 - val_loss: 0.3060 - val_acc: 0.8733\n",
      "Epoch 51/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2206 - acc: 0.9144 - val_loss: 0.2951 - val_acc: 0.8806\n",
      "Epoch 52/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2194 - acc: 0.9153 - val_loss: 0.2807 - val_acc: 0.8793\n",
      "Epoch 53/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2185 - acc: 0.9152 - val_loss: 0.3212 - val_acc: 0.8646\n",
      "Epoch 54/10000\n",
      "97312/97312 [==============================] - 6s - loss: 0.2181 - acc: 0.9150 - val_loss: 0.3212 - val_acc: 0.8734\n",
      "97280/97312 [============================>.] - ETA: 0sKF_7\n",
      "Train on 97375 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.4633 - acc: 0.7953 - val_loss: 0.5117 - val_acc: 0.7428\n",
      "Epoch 2/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.4006 - acc: 0.8328 - val_loss: 0.4393 - val_acc: 0.8135\n",
      "Epoch 3/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.3631 - acc: 0.8486 - val_loss: 0.3782 - val_acc: 0.8367\n",
      "Epoch 4/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.3404 - acc: 0.8578 - val_loss: 0.3503 - val_acc: 0.8403\n",
      "Epoch 5/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.3236 - acc: 0.8657 - val_loss: 0.4239 - val_acc: 0.8354\n",
      "Epoch 6/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.3128 - acc: 0.8712 - val_loss: 0.3944 - val_acc: 0.8390\n",
      "Epoch 7/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.3038 - acc: 0.8751 - val_loss: 0.4543 - val_acc: 0.8193\n",
      "Epoch 8/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2961 - acc: 0.8789 - val_loss: 0.3824 - val_acc: 0.8432\n",
      "Epoch 9/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2907 - acc: 0.8814 - val_loss: 0.3387 - val_acc: 0.8546\n",
      "Epoch 10/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2846 - acc: 0.8851 - val_loss: 0.2946 - val_acc: 0.8727\n",
      "Epoch 11/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2803 - acc: 0.8862 - val_loss: 0.3885 - val_acc: 0.8423\n",
      "Epoch 12/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2759 - acc: 0.8882 - val_loss: 0.3263 - val_acc: 0.8662\n",
      "Epoch 13/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2716 - acc: 0.8895 - val_loss: 0.2597 - val_acc: 0.8908\n",
      "Epoch 14/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2686 - acc: 0.8916 - val_loss: 0.3105 - val_acc: 0.8731\n",
      "Epoch 15/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2645 - acc: 0.8934 - val_loss: 0.4575 - val_acc: 0.8179\n",
      "Epoch 16/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2604 - acc: 0.8954 - val_loss: 0.2988 - val_acc: 0.8687\n",
      "Epoch 17/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2586 - acc: 0.8961 - val_loss: 0.3477 - val_acc: 0.8652\n",
      "Epoch 18/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2565 - acc: 0.8974 - val_loss: 0.3070 - val_acc: 0.8739\n",
      "Epoch 19/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2538 - acc: 0.8994 - val_loss: 0.2535 - val_acc: 0.8881\n",
      "Epoch 20/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2511 - acc: 0.8996 - val_loss: 0.3216 - val_acc: 0.8641\n",
      "Epoch 21/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2495 - acc: 0.9017 - val_loss: 0.4002 - val_acc: 0.8422\n",
      "Epoch 22/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2470 - acc: 0.9018 - val_loss: 0.3719 - val_acc: 0.8462\n",
      "Epoch 23/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2455 - acc: 0.9029 - val_loss: 0.4118 - val_acc: 0.8458\n",
      "Epoch 24/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2436 - acc: 0.9030 - val_loss: 0.2438 - val_acc: 0.9017\n",
      "Epoch 25/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2435 - acc: 0.9032 - val_loss: 0.3499 - val_acc: 0.8576\n",
      "Epoch 26/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2413 - acc: 0.9047 - val_loss: 0.2949 - val_acc: 0.8759\n",
      "Epoch 27/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2391 - acc: 0.9059 - val_loss: 0.3088 - val_acc: 0.8699\n",
      "Epoch 28/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2368 - acc: 0.9074 - val_loss: 0.2227 - val_acc: 0.9154\n",
      "Epoch 29/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2371 - acc: 0.9064 - val_loss: 0.4270 - val_acc: 0.8362\n",
      "Epoch 30/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2346 - acc: 0.9071 - val_loss: 0.3226 - val_acc: 0.8679\n",
      "Epoch 31/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2340 - acc: 0.9082 - val_loss: 0.3009 - val_acc: 0.8726\n",
      "Epoch 32/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2326 - acc: 0.9083 - val_loss: 0.2548 - val_acc: 0.8919\n",
      "Epoch 33/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2315 - acc: 0.9092 - val_loss: 0.3817 - val_acc: 0.8534\n",
      "Epoch 34/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2294 - acc: 0.9102 - val_loss: 0.2989 - val_acc: 0.8720\n",
      "Epoch 35/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2276 - acc: 0.9109 - val_loss: 0.2583 - val_acc: 0.8889\n",
      "Epoch 36/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2277 - acc: 0.9107 - val_loss: 0.3680 - val_acc: 0.8548\n",
      "Epoch 37/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2254 - acc: 0.9116 - val_loss: 0.3986 - val_acc: 0.8552\n",
      "Epoch 38/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2265 - acc: 0.9117 - val_loss: 0.2927 - val_acc: 0.8760\n",
      "Epoch 39/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2248 - acc: 0.9124 - val_loss: 0.5252 - val_acc: 0.8175\n",
      "Epoch 40/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2242 - acc: 0.9128 - val_loss: 0.2939 - val_acc: 0.8773\n",
      "Epoch 41/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2227 - acc: 0.9139 - val_loss: 0.3172 - val_acc: 0.8723\n",
      "Epoch 42/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2218 - acc: 0.9137 - val_loss: 0.3749 - val_acc: 0.8549\n",
      "Epoch 43/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2197 - acc: 0.9149 - val_loss: 0.3321 - val_acc: 0.8652\n",
      "Epoch 44/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2192 - acc: 0.9153 - val_loss: 0.2462 - val_acc: 0.8977\n",
      "Epoch 45/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2189 - acc: 0.9152 - val_loss: 0.3865 - val_acc: 0.8497\n",
      "Epoch 46/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2188 - acc: 0.9151 - val_loss: 0.3723 - val_acc: 0.8603\n",
      "Epoch 47/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2168 - acc: 0.9161 - val_loss: 0.3250 - val_acc: 0.8633\n",
      "Epoch 48/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2157 - acc: 0.9169 - val_loss: 0.2802 - val_acc: 0.8835\n",
      "Epoch 49/10000\n",
      "97375/97375 [==============================] - 6s - loss: 0.2156 - acc: 0.9170 - val_loss: 0.2828 - val_acc: 0.8807\n",
      "97280/97375 [============================>.] - ETA: 0sKF_8\n",
      "Train on 97604 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.4520 - acc: 0.8015 - val_loss: 0.4364 - val_acc: 0.8080\n",
      "Epoch 2/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.3881 - acc: 0.8411 - val_loss: 0.4093 - val_acc: 0.8356\n",
      "Epoch 3/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.3553 - acc: 0.8548 - val_loss: 0.3800 - val_acc: 0.8432\n",
      "Epoch 4/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.3358 - acc: 0.8615 - val_loss: 0.3932 - val_acc: 0.8406\n",
      "Epoch 5/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.3186 - acc: 0.8695 - val_loss: 0.3381 - val_acc: 0.8612\n",
      "Epoch 6/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.3086 - acc: 0.8750 - val_loss: 0.3473 - val_acc: 0.8480\n",
      "Epoch 7/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2997 - acc: 0.8787 - val_loss: 0.3400 - val_acc: 0.8478\n",
      "Epoch 8/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2927 - acc: 0.8811 - val_loss: 0.2803 - val_acc: 0.8723\n",
      "Epoch 9/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2863 - acc: 0.8837 - val_loss: 0.2834 - val_acc: 0.8703\n",
      "Epoch 10/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2809 - acc: 0.8876 - val_loss: 0.3614 - val_acc: 0.8434\n",
      "Epoch 11/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2772 - acc: 0.8882 - val_loss: 0.3206 - val_acc: 0.8582\n",
      "Epoch 12/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2713 - acc: 0.8910 - val_loss: 0.3122 - val_acc: 0.8688\n",
      "Epoch 13/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2675 - acc: 0.8923 - val_loss: 0.3315 - val_acc: 0.8614\n",
      "Epoch 14/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2636 - acc: 0.8941 - val_loss: 0.3053 - val_acc: 0.8601\n",
      "Epoch 15/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2620 - acc: 0.8954 - val_loss: 0.3772 - val_acc: 0.8411\n",
      "Epoch 16/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2584 - acc: 0.8963 - val_loss: 0.3123 - val_acc: 0.8638\n",
      "Epoch 17/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2558 - acc: 0.8976 - val_loss: 0.2612 - val_acc: 0.8815\n",
      "Epoch 18/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2528 - acc: 0.8987 - val_loss: 0.2903 - val_acc: 0.8726\n",
      "Epoch 19/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2512 - acc: 0.8997 - val_loss: 0.3562 - val_acc: 0.8537\n",
      "Epoch 20/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2482 - acc: 0.9011 - val_loss: 0.3759 - val_acc: 0.8566\n",
      "Epoch 21/10000\n",
      "97604/97604 [==============================] - 7s - loss: 0.2477 - acc: 0.9015 - val_loss: 0.3373 - val_acc: 0.8631\n",
      "Epoch 22/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2458 - acc: 0.9015 - val_loss: 0.2830 - val_acc: 0.8769\n",
      "Epoch 23/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2440 - acc: 0.9030 - val_loss: 0.3488 - val_acc: 0.8584\n",
      "Epoch 24/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97604/97604 [==============================] - 6s - loss: 0.2415 - acc: 0.9044 - val_loss: 0.3522 - val_acc: 0.8446\n",
      "Epoch 25/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2397 - acc: 0.9044 - val_loss: 0.3588 - val_acc: 0.8540\n",
      "Epoch 26/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2389 - acc: 0.9050 - val_loss: 0.2900 - val_acc: 0.8745\n",
      "Epoch 27/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2371 - acc: 0.9060 - val_loss: 0.3827 - val_acc: 0.8523\n",
      "Epoch 28/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2366 - acc: 0.9068 - val_loss: 0.3375 - val_acc: 0.8647\n",
      "Epoch 29/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2348 - acc: 0.9074 - val_loss: 0.3684 - val_acc: 0.8493\n",
      "Epoch 30/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2333 - acc: 0.9074 - val_loss: 0.3222 - val_acc: 0.8592\n",
      "Epoch 31/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2325 - acc: 0.9081 - val_loss: 0.3120 - val_acc: 0.8650\n",
      "Epoch 32/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2308 - acc: 0.9087 - val_loss: 0.2993 - val_acc: 0.8686\n",
      "Epoch 33/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2301 - acc: 0.9090 - val_loss: 0.3107 - val_acc: 0.8601\n",
      "Epoch 34/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2282 - acc: 0.9098 - val_loss: 0.3247 - val_acc: 0.8609\n",
      "Epoch 35/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2278 - acc: 0.9094 - val_loss: 0.3407 - val_acc: 0.8612\n",
      "Epoch 36/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2262 - acc: 0.9106 - val_loss: 0.4486 - val_acc: 0.8318\n",
      "Epoch 37/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2250 - acc: 0.9115 - val_loss: 0.3828 - val_acc: 0.8503\n",
      "Epoch 38/10000\n",
      "97604/97604 [==============================] - 6s - loss: 0.2239 - acc: 0.9112 - val_loss: 0.3545 - val_acc: 0.8611\n",
      "97440/97604 [============================>.] - ETA: 0sKF_9\n",
      "Train on 97479 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.4701 - acc: 0.7891 - val_loss: 0.5080 - val_acc: 0.7537\n",
      "Epoch 2/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.4055 - acc: 0.8307 - val_loss: 0.4375 - val_acc: 0.8064\n",
      "Epoch 3/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3712 - acc: 0.8455 - val_loss: 0.4074 - val_acc: 0.8326\n",
      "Epoch 4/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3489 - acc: 0.8543 - val_loss: 0.3254 - val_acc: 0.8654\n",
      "Epoch 5/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3334 - acc: 0.8602 - val_loss: 0.3814 - val_acc: 0.8445\n",
      "Epoch 6/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3221 - acc: 0.8657 - val_loss: 0.3736 - val_acc: 0.8423\n",
      "Epoch 7/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3145 - acc: 0.8695 - val_loss: 0.3584 - val_acc: 0.8377\n",
      "Epoch 8/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3066 - acc: 0.8727 - val_loss: 0.3224 - val_acc: 0.8578\n",
      "Epoch 9/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.3002 - acc: 0.8746 - val_loss: 0.3740 - val_acc: 0.8327\n",
      "Epoch 10/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2944 - acc: 0.8779 - val_loss: 0.4099 - val_acc: 0.8367\n",
      "Epoch 11/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2905 - acc: 0.8795 - val_loss: 0.3932 - val_acc: 0.8223\n",
      "Epoch 12/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2869 - acc: 0.8813 - val_loss: 0.3241 - val_acc: 0.8554\n",
      "Epoch 13/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2815 - acc: 0.8837 - val_loss: 0.4079 - val_acc: 0.8218\n",
      "Epoch 14/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2787 - acc: 0.8853 - val_loss: 0.3625 - val_acc: 0.8416\n",
      "Epoch 15/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2744 - acc: 0.8875 - val_loss: 0.3398 - val_acc: 0.8607\n",
      "Epoch 16/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2728 - acc: 0.8873 - val_loss: 0.3334 - val_acc: 0.8578\n",
      "Epoch 17/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2703 - acc: 0.8897 - val_loss: 0.3425 - val_acc: 0.8481\n",
      "Epoch 18/10000\n",
      "97479/97479 [==============================] - 7s - loss: 0.2667 - acc: 0.8919 - val_loss: 0.3053 - val_acc: 0.8662\n",
      "Epoch 19/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2640 - acc: 0.8927 - val_loss: 0.3713 - val_acc: 0.8335\n",
      "Epoch 20/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2624 - acc: 0.8926 - val_loss: 0.3237 - val_acc: 0.8617\n",
      "Epoch 21/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2596 - acc: 0.8944 - val_loss: 0.2892 - val_acc: 0.8748\n",
      "Epoch 22/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2586 - acc: 0.8948 - val_loss: 0.3596 - val_acc: 0.8526\n",
      "Epoch 23/10000\n",
      "97479/97479 [==============================] - 7s - loss: 0.2568 - acc: 0.8958 - val_loss: 0.3647 - val_acc: 0.8506\n",
      "Epoch 24/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2539 - acc: 0.8969 - val_loss: 0.3534 - val_acc: 0.8503\n",
      "Epoch 25/10000\n",
      "97479/97479 [==============================] - 7s - loss: 0.2527 - acc: 0.8971 - val_loss: 0.3690 - val_acc: 0.8577\n",
      "Epoch 26/10000\n",
      "97479/97479 [==============================] - 7s - loss: 0.2501 - acc: 0.8983 - val_loss: 0.2987 - val_acc: 0.8767\n",
      "Epoch 27/10000\n",
      "97479/97479 [==============================] - 7s - loss: 0.2497 - acc: 0.8994 - val_loss: 0.3424 - val_acc: 0.8485\n",
      "Epoch 28/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2473 - acc: 0.9005 - val_loss: 0.3669 - val_acc: 0.8564\n",
      "Epoch 29/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2458 - acc: 0.9008 - val_loss: 0.2774 - val_acc: 0.8828\n",
      "Epoch 30/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2442 - acc: 0.9014 - val_loss: 0.3205 - val_acc: 0.8702\n",
      "Epoch 31/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2435 - acc: 0.9017 - val_loss: 0.3273 - val_acc: 0.8612\n",
      "Epoch 32/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2415 - acc: 0.9031 - val_loss: 0.3936 - val_acc: 0.8301\n",
      "Epoch 33/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2404 - acc: 0.9035 - val_loss: 0.3270 - val_acc: 0.8514\n",
      "Epoch 34/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2392 - acc: 0.9036 - val_loss: 0.3613 - val_acc: 0.8513\n",
      "Epoch 35/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2384 - acc: 0.9040 - val_loss: 0.3624 - val_acc: 0.8587\n",
      "Epoch 36/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2367 - acc: 0.9052 - val_loss: 0.3321 - val_acc: 0.8591\n",
      "Epoch 37/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2356 - acc: 0.9054 - val_loss: 0.3367 - val_acc: 0.86770.904 - ET\n",
      "Epoch 38/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2343 - acc: 0.9058 - val_loss: 0.3433 - val_acc: 0.8636\n",
      "Epoch 39/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2336 - acc: 0.9062 - val_loss: 0.3345 - val_acc: 0.8622\n",
      "Epoch 40/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2321 - acc: 0.9070 - val_loss: 0.3469 - val_acc: 0.8535\n",
      "Epoch 41/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2318 - acc: 0.9077 - val_loss: 0.3993 - val_acc: 0.8460\n",
      "Epoch 42/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2298 - acc: 0.9083 - val_loss: 0.3759 - val_acc: 0.8508\n",
      "Epoch 43/10000\n",
      "97479/97479 [==============================] - 7s - loss: 0.2295 - acc: 0.9081 - val_loss: 0.3423 - val_acc: 0.8643\n",
      "Epoch 44/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2280 - acc: 0.9090 - val_loss: 0.3434 - val_acc: 0.8601\n",
      "Epoch 45/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2275 - acc: 0.9091 - val_loss: 0.3648 - val_acc: 0.8561\n",
      "Epoch 46/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2271 - acc: 0.9094 - val_loss: 0.3280 - val_acc: 0.8656\n",
      "Epoch 47/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2259 - acc: 0.9102 - val_loss: 0.3220 - val_acc: 0.8695\n",
      "Epoch 48/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2249 - acc: 0.9103 - val_loss: 0.3407 - val_acc: 0.8569\n",
      "Epoch 49/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2242 - acc: 0.9109 - val_loss: 0.3037 - val_acc: 0.8753\n",
      "Epoch 50/10000\n",
      "97479/97479 [==============================] - 6s - loss: 0.2240 - acc: 0.9113 - val_loss: 0.3551 - val_acc: 0.8618\n",
      "96896/97479 [============================>.] - ETA: 0sKF_10\n",
      "Train on 97528 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.4621 - acc: 0.7928 - val_loss: 0.4899 - val_acc: 0.7629\n",
      "Epoch 2/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.4020 - acc: 0.8310 - val_loss: 0.4584 - val_acc: 0.7882\n",
      "Epoch 3/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.3676 - acc: 0.8466 - val_loss: 0.3548 - val_acc: 0.8442\n",
      "Epoch 4/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.3466 - acc: 0.8550 - val_loss: 0.3953 - val_acc: 0.8215\n",
      "Epoch 5/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.3282 - acc: 0.8639 - val_loss: 0.3779 - val_acc: 0.8321\n",
      "Epoch 6/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.3169 - acc: 0.8696 - val_loss: 0.3342 - val_acc: 0.8525\n",
      "Epoch 7/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.3087 - acc: 0.8716 - val_loss: 0.2947 - val_acc: 0.8677\n",
      "Epoch 8/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.3013 - acc: 0.8759 - val_loss: 0.3640 - val_acc: 0.8437\n",
      "Epoch 9/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2952 - acc: 0.8775 - val_loss: 0.3732 - val_acc: 0.8383\n",
      "Epoch 10/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2899 - acc: 0.8809 - val_loss: 0.2843 - val_acc: 0.8731\n",
      "Epoch 11/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2832 - acc: 0.8828 - val_loss: 0.3741 - val_acc: 0.8457\n",
      "Epoch 12/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2789 - acc: 0.8850 - val_loss: 0.3061 - val_acc: 0.8601\n",
      "Epoch 13/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2756 - acc: 0.8865 - val_loss: 0.2303 - val_acc: 0.9125\n",
      "Epoch 14/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2723 - acc: 0.8881 - val_loss: 0.2694 - val_acc: 0.8804\n",
      "Epoch 15/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2692 - acc: 0.8901 - val_loss: 0.3368 - val_acc: 0.8669\n",
      "Epoch 16/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2645 - acc: 0.8926 - val_loss: 0.3407 - val_acc: 0.8547\n",
      "Epoch 17/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2616 - acc: 0.8935 - val_loss: 0.3665 - val_acc: 0.8470\n",
      "Epoch 18/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2594 - acc: 0.8950 - val_loss: 0.2737 - val_acc: 0.8775\n",
      "Epoch 19/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2577 - acc: 0.8953 - val_loss: 0.3964 - val_acc: 0.8444\n",
      "Epoch 20/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2546 - acc: 0.8978 - val_loss: 0.3924 - val_acc: 0.8473\n",
      "Epoch 21/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2538 - acc: 0.8975 - val_loss: 0.3898 - val_acc: 0.8462\n",
      "Epoch 22/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2508 - acc: 0.8989 - val_loss: 0.3455 - val_acc: 0.8583\n",
      "Epoch 23/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2497 - acc: 0.8994 - val_loss: 0.2825 - val_acc: 0.8769\n",
      "Epoch 24/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2493 - acc: 0.8997 - val_loss: 0.4554 - val_acc: 0.8289\n",
      "Epoch 25/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2469 - acc: 0.9011 - val_loss: 0.3406 - val_acc: 0.8521\n",
      "Epoch 26/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2450 - acc: 0.9023 - val_loss: 0.3709 - val_acc: 0.8556\n",
      "Epoch 27/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2435 - acc: 0.9022 - val_loss: 0.3249 - val_acc: 0.8591\n",
      "Epoch 28/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2420 - acc: 0.9032 - val_loss: 0.3591 - val_acc: 0.8480\n",
      "Epoch 29/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2413 - acc: 0.9042 - val_loss: 0.3223 - val_acc: 0.8662\n",
      "Epoch 30/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2403 - acc: 0.9039 - val_loss: 0.4309 - val_acc: 0.8367\n",
      "Epoch 31/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2388 - acc: 0.9046 - val_loss: 0.5072 - val_acc: 0.8235\n",
      "Epoch 32/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2391 - acc: 0.9048 - val_loss: 0.3887 - val_acc: 0.8569\n",
      "Epoch 33/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2372 - acc: 0.9068 - val_loss: 0.3008 - val_acc: 0.8693\n",
      "Epoch 34/10000\n",
      "97528/97528 [==============================] - 6s - loss: 0.2354 - acc: 0.9066 - val_loss: 0.3547 - val_acc: 0.8500\n",
      "97248/97528 [============================>.] - ETA: 0s\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'MLP'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "    \n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Train, validation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train)\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    \n",
    "    # Oversampling\n",
    "    sampling = SMOTE(kind='borderline2',k_neighbors=5, random_state=42, n_jobs=4)\n",
    "    x_train, y_train = sampling.fit_sample(x_train, y_train)\n",
    "    \n",
    "    # one hot\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_val = to_categorical(y_val)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i)\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, activation='tanh', input_dim=x_train.shape[1]))\n",
    "    model.add(Dense(80, activation='tanh'))\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train,y_train,\n",
    "                  batch_size=150,\n",
    "                  epochs=10000,\n",
    "                  callbacks=[EarlyStopping(patience=20)],\n",
    "                  validation_data=(x_val, y_val))\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred_proba = model.predict_proba(x_test)\n",
    "    y_pred = y_pred_proba.argmax(axis=1)\n",
    "    \n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train[:,1], model.predict_proba(x_train)[:,1])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred_proba[:,1])\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "    clear_session()\n",
    "\n",
    "print()\n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.973971</td>\n",
       "      <td>0.750479</td>\n",
       "      <td>0.750479</td>\n",
       "      <td>0.558402</td>\n",
       "      <td>0.686036</td>\n",
       "      <td>0.570466</td>\n",
       "      <td>0.858871</td>\n",
       "      <td>00:06:48.197081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.967796</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.565344</td>\n",
       "      <td>0.694973</td>\n",
       "      <td>0.582014</td>\n",
       "      <td>0.869920</td>\n",
       "      <td>00:04:21.071317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.972562</td>\n",
       "      <td>0.752048</td>\n",
       "      <td>0.752048</td>\n",
       "      <td>0.558269</td>\n",
       "      <td>0.704524</td>\n",
       "      <td>0.567260</td>\n",
       "      <td>0.845435</td>\n",
       "      <td>00:05:47.229932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.973757</td>\n",
       "      <td>0.769916</td>\n",
       "      <td>0.769916</td>\n",
       "      <td>0.566154</td>\n",
       "      <td>0.684535</td>\n",
       "      <td>0.584087</td>\n",
       "      <td>0.877401</td>\n",
       "      <td>00:06:32.804624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.956206</td>\n",
       "      <td>0.748364</td>\n",
       "      <td>0.748364</td>\n",
       "      <td>0.543721</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.533370</td>\n",
       "      <td>0.796632</td>\n",
       "      <td>00:03:12.822093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.971500</td>\n",
       "      <td>0.791269</td>\n",
       "      <td>0.791269</td>\n",
       "      <td>0.570713</td>\n",
       "      <td>0.716920</td>\n",
       "      <td>0.589376</td>\n",
       "      <td>0.869245</td>\n",
       "      <td>00:05:40.849149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.973321</td>\n",
       "      <td>0.770329</td>\n",
       "      <td>0.770329</td>\n",
       "      <td>0.570420</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.590276</td>\n",
       "      <td>0.879768</td>\n",
       "      <td>00:05:07.867357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.969258</td>\n",
       "      <td>0.742244</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>0.558663</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.571230</td>\n",
       "      <td>0.860958</td>\n",
       "      <td>00:04:09.907779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.971357</td>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.772339</td>\n",
       "      <td>0.567908</td>\n",
       "      <td>0.715305</td>\n",
       "      <td>0.584669</td>\n",
       "      <td>0.864492</td>\n",
       "      <td>00:05:27.568890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.967843</td>\n",
       "      <td>0.764807</td>\n",
       "      <td>0.768140</td>\n",
       "      <td>0.560584</td>\n",
       "      <td>0.707977</td>\n",
       "      <td>0.571605</td>\n",
       "      <td>0.850414</td>\n",
       "      <td>00:03:28.634043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.969757</td>\n",
       "      <td>0.761782</td>\n",
       "      <td>0.762781</td>\n",
       "      <td>0.562018</td>\n",
       "      <td>0.697980</td>\n",
       "      <td>0.574435</td>\n",
       "      <td>0.857314</td>\n",
       "      <td>00:05:03.695226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.011823</td>\n",
       "      <td>0.015816</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>00:01:09.830890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.973971  0.750479  0.750479   0.558402  0.686036  0.570466   \n",
       "KF_2      0.967796  0.759358  0.759358   0.565344  0.694973  0.582014   \n",
       "KF_3      0.972562  0.752048  0.752048   0.558269  0.704524  0.567260   \n",
       "KF_4      0.973757  0.769916  0.769916   0.566154  0.684535  0.584087   \n",
       "KF_5      0.956206  0.748364  0.748364   0.543721  0.690265  0.533370   \n",
       "KF_6      0.971500  0.791269  0.791269   0.570713  0.716920  0.589376   \n",
       "KF_7      0.973321  0.770329  0.770329   0.570420  0.695324  0.590276   \n",
       "KF_8      0.969258  0.742244  0.745566   0.558663  0.683938  0.571230   \n",
       "KF_9      0.971357  0.769006  0.772339   0.567908  0.715305  0.584669   \n",
       "KF_10     0.967843  0.764807  0.768140   0.560584  0.707977  0.571605   \n",
       "Media     0.969757  0.761782  0.762781   0.562018  0.697980  0.574435   \n",
       "STD       0.005013  0.013639  0.013498   0.007644  0.011823  0.015816   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.858871 00:06:48.197081  \n",
       "KF_2   0.869920 00:04:21.071317  \n",
       "KF_3   0.845435 00:05:47.229932  \n",
       "KF_4   0.877401 00:06:32.804624  \n",
       "KF_5   0.796632 00:03:12.822093  \n",
       "KF_6   0.869245 00:05:40.849149  \n",
       "KF_7   0.879768 00:05:07.867357  \n",
       "KF_8   0.860958 00:04:09.907779  \n",
       "KF_9   0.864492 00:05:27.568890  \n",
       "KF_10  0.850414 00:03:28.634043  \n",
       "Media  0.857314 00:05:03.695226  \n",
       "STD    0.022687 00:01:09.830890  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_name)\n",
    "\n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('K-Fold: 10')\n",
    "\n",
    "models.sort_values(['F1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
