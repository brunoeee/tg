{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# time\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ETL\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend import clear_session\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# K-fold\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "models = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(76020, 287)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "\n",
    "## Remove colunas constantes\n",
    "colsToRemove = []\n",
    "for col in df.columns:\n",
    "    if df[col].std() == 0:\n",
    "        colsToRemove.append(col)\n",
    "df.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "## Remove colunas multiplas\n",
    "colsToRemove = []\n",
    "columns = df.columns\n",
    "for i in range(len(columns)-1):\n",
    "    print(i, end=\"\\r\")\n",
    "    v = df[columns[i]]\n",
    "    for j in range(i+1,len(columns)):\n",
    "        m = df.loc[(df[columns[j]]*v) != 0, [columns[j], columns[i]]]\n",
    "        if m.shape[0] > 0:\n",
    "            c = m.iloc[0,0]/m.iloc[0,1]\n",
    "            if np.array_equal(c*v.values,df[columns[j]].values):\n",
    "                colsToRemove.append(columns[j])\n",
    "df.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "## Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "## Split (X,Y) \n",
    "x_data = df.drop(['ID','TARGET'], axis=1)\n",
    "y_data = df['TARGET'].copy()\n",
    "\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_10            \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.726399</td>\n",
       "      <td>0.700542</td>\n",
       "      <td>0.700542</td>\n",
       "      <td>0.534536</td>\n",
       "      <td>0.700542</td>\n",
       "      <td>0.481041</td>\n",
       "      <td>0.687886</td>\n",
       "      <td>00:24:14.611310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.722076</td>\n",
       "      <td>0.721624</td>\n",
       "      <td>0.721624</td>\n",
       "      <td>0.537637</td>\n",
       "      <td>0.721624</td>\n",
       "      <td>0.482152</td>\n",
       "      <td>0.682494</td>\n",
       "      <td>00:23:03.004579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.725755</td>\n",
       "      <td>0.702319</td>\n",
       "      <td>0.702319</td>\n",
       "      <td>0.534851</td>\n",
       "      <td>0.702319</td>\n",
       "      <td>0.481539</td>\n",
       "      <td>0.688240</td>\n",
       "      <td>00:23:26.042186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.726799</td>\n",
       "      <td>0.698294</td>\n",
       "      <td>0.698294</td>\n",
       "      <td>0.534277</td>\n",
       "      <td>0.698294</td>\n",
       "      <td>0.481506</td>\n",
       "      <td>0.689687</td>\n",
       "      <td>00:23:30.962955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.726463</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.535344</td>\n",
       "      <td>0.706703</td>\n",
       "      <td>0.480484</td>\n",
       "      <td>0.684425</td>\n",
       "      <td>00:23:39.778466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.723543</td>\n",
       "      <td>0.713091</td>\n",
       "      <td>0.713091</td>\n",
       "      <td>0.536204</td>\n",
       "      <td>0.713091</td>\n",
       "      <td>0.480143</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>00:23:24.295193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.725067</td>\n",
       "      <td>0.710454</td>\n",
       "      <td>0.710454</td>\n",
       "      <td>0.535838</td>\n",
       "      <td>0.710454</td>\n",
       "      <td>0.480192</td>\n",
       "      <td>0.682452</td>\n",
       "      <td>00:23:24.383880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.671681</td>\n",
       "      <td>0.671681</td>\n",
       "      <td>0.530099</td>\n",
       "      <td>0.671681</td>\n",
       "      <td>0.478446</td>\n",
       "      <td>0.693633</td>\n",
       "      <td>00:23:28.400867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.725907</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>0.533648</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>0.477870</td>\n",
       "      <td>0.682805</td>\n",
       "      <td>00:23:43.480291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.722965</td>\n",
       "      <td>0.699383</td>\n",
       "      <td>0.699383</td>\n",
       "      <td>0.533999</td>\n",
       "      <td>0.699383</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.683463</td>\n",
       "      <td>00:23:30.173608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.725131</td>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.534643</td>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.480190</td>\n",
       "      <td>0.685648</td>\n",
       "      <td>00:23:32.513333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>00:00:17.367655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.726399  0.700542  0.700542   0.534536  0.700542  0.481041   \n",
       "KF_2      0.722076  0.721624  0.721624   0.537637  0.721624  0.482152   \n",
       "KF_3      0.725755  0.702319  0.702319   0.534851  0.702319  0.481539   \n",
       "KF_4      0.726799  0.698294  0.698294   0.534277  0.698294  0.481506   \n",
       "KF_5      0.726463  0.706703  0.706703   0.535344  0.706703  0.480484   \n",
       "KF_6      0.723543  0.713091  0.713091   0.536204  0.713091  0.480143   \n",
       "KF_7      0.725067  0.710454  0.710454   0.535838  0.710454  0.480192   \n",
       "KF_8      0.726333  0.671681  0.671681   0.530099  0.671681  0.478446   \n",
       "KF_9      0.725907  0.697442  0.697442   0.533648  0.697442  0.477870   \n",
       "KF_10     0.722965  0.699383  0.699383   0.533999  0.699383  0.478528   \n",
       "Media     0.725131  0.702153  0.702153   0.534643  0.702153  0.480190   \n",
       "STD       0.001586  0.012507  0.012507   0.001886  0.012507  0.001393   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.687886 00:24:14.611310  \n",
       "KF_2   0.682494 00:23:03.004579  \n",
       "KF_3   0.688240 00:23:26.042186  \n",
       "KF_4   0.689687 00:23:30.962955  \n",
       "KF_5   0.684425 00:23:39.778466  \n",
       "KF_6   0.681400 00:23:24.295193  \n",
       "KF_7   0.682452 00:23:24.383880  \n",
       "KF_8   0.693633 00:23:28.400867  \n",
       "KF_9   0.682805 00:23:43.480291  \n",
       "KF_10  0.683463 00:23:30.173608  \n",
       "Media  0.685648 00:23:32.513333  \n",
       "STD    0.003800 00:00:17.367655  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'SVM(RBF)'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i+'            ', end=\"\\r\")\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = SVC(C=0.1, kernel='rbf', class_weight = 'balanced')\n",
    "    model.fit(x_train, y_train)\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train, model.predict(x_train))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred)\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "    \n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()\n",
    "    \n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_10            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.891783</td>\n",
       "      <td>0.832640</td>\n",
       "      <td>0.832640</td>\n",
       "      <td>0.558305</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.558292</td>\n",
       "      <td>0.814547</td>\n",
       "      <td>00:03:07.567300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.864993</td>\n",
       "      <td>0.864993</td>\n",
       "      <td>0.565929</td>\n",
       "      <td>0.790477</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.808628</td>\n",
       "      <td>00:03:02.246706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.890878</td>\n",
       "      <td>0.838726</td>\n",
       "      <td>0.842048</td>\n",
       "      <td>0.562639</td>\n",
       "      <td>0.760630</td>\n",
       "      <td>0.565295</td>\n",
       "      <td>0.818600</td>\n",
       "      <td>00:03:02.167665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.891146</td>\n",
       "      <td>0.838793</td>\n",
       "      <td>0.838793</td>\n",
       "      <td>0.564327</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.567590</td>\n",
       "      <td>0.818863</td>\n",
       "      <td>00:03:05.577534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.891183</td>\n",
       "      <td>0.816694</td>\n",
       "      <td>0.820016</td>\n",
       "      <td>0.554370</td>\n",
       "      <td>0.728264</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>0.811497</td>\n",
       "      <td>00:03:03.427888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.890470</td>\n",
       "      <td>0.840036</td>\n",
       "      <td>0.843358</td>\n",
       "      <td>0.559838</td>\n",
       "      <td>0.765290</td>\n",
       "      <td>0.556377</td>\n",
       "      <td>0.803078</td>\n",
       "      <td>00:03:01.279845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.890959</td>\n",
       "      <td>0.834421</td>\n",
       "      <td>0.834421</td>\n",
       "      <td>0.561031</td>\n",
       "      <td>0.762755</td>\n",
       "      <td>0.560469</td>\n",
       "      <td>0.810445</td>\n",
       "      <td>00:03:03.102794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.890999</td>\n",
       "      <td>0.823296</td>\n",
       "      <td>0.823296</td>\n",
       "      <td>0.558404</td>\n",
       "      <td>0.746537</td>\n",
       "      <td>0.557895</td>\n",
       "      <td>0.812944</td>\n",
       "      <td>00:03:01.128614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.891617</td>\n",
       "      <td>0.827172</td>\n",
       "      <td>0.830505</td>\n",
       "      <td>0.559273</td>\n",
       "      <td>0.754419</td>\n",
       "      <td>0.558222</td>\n",
       "      <td>0.810683</td>\n",
       "      <td>00:03:01.300135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.891046</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.562272</td>\n",
       "      <td>0.769077</td>\n",
       "      <td>0.562291</td>\n",
       "      <td>0.811209</td>\n",
       "      <td>00:03:01.209207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.890878</td>\n",
       "      <td>0.835689</td>\n",
       "      <td>0.837019</td>\n",
       "      <td>0.560639</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.560472</td>\n",
       "      <td>0.812049</td>\n",
       "      <td>00:03:02.900768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>00:00:02.035112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.891783  0.832640  0.832640   0.558305  0.744186  0.558292   \n",
       "KF_2      0.888700  0.864993  0.864993   0.565929  0.790477  0.566144   \n",
       "KF_3      0.890878  0.838726  0.842048   0.562639  0.760630  0.565295   \n",
       "KF_4      0.891146  0.838793  0.838793   0.564327  0.768730  0.567590   \n",
       "KF_5      0.891183  0.816694  0.820016   0.554370  0.728264  0.552147   \n",
       "KF_6      0.890470  0.840036  0.843358   0.559838  0.765290  0.556377   \n",
       "KF_7      0.890959  0.834421  0.834421   0.561031  0.762755  0.560469   \n",
       "KF_8      0.890999  0.823296  0.823296   0.558404  0.746537  0.557895   \n",
       "KF_9      0.891617  0.827172  0.830505   0.559273  0.754419  0.558222   \n",
       "KF_10     0.891046  0.840121  0.840121   0.562272  0.769077  0.562291   \n",
       "Media     0.890878  0.835689  0.837019   0.560639  0.759036  0.560472   \n",
       "STD       0.000805  0.012304  0.011860   0.003173  0.016074  0.004604   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.814547 00:03:07.567300  \n",
       "KF_2   0.808628 00:03:02.246706  \n",
       "KF_3   0.818600 00:03:02.167665  \n",
       "KF_4   0.818863 00:03:05.577534  \n",
       "KF_5   0.811497 00:03:03.427888  \n",
       "KF_6   0.803078 00:03:01.279845  \n",
       "KF_7   0.810445 00:03:03.102794  \n",
       "KF_8   0.812944 00:03:01.128614  \n",
       "KF_9   0.810683 00:03:01.300135  \n",
       "KF_10  0.811209 00:03:01.209207  \n",
       "Media  0.812049 00:03:02.900768  \n",
       "STD    0.004405 00:00:02.035112  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'RF'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i+'            ', end=\"\\r\")\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = RandomForestClassifier(\n",
    "                                   n_estimators = 800,\n",
    "                                   min_samples_leaf = 85,\n",
    "                                   max_features = 0.3,\n",
    "                                   class_weight = 'balanced',\n",
    "                                   n_jobs=-1\n",
    "                                  )\n",
    "    model.fit(x_train, y_train)\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train, model.predict_proba(x_train)[:,1])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred_proba)\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "\n",
    "print()\n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()\n",
    "    \n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_10            \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.890837</td>\n",
       "      <td>0.832903</td>\n",
       "      <td>0.836225</td>\n",
       "      <td>0.680324</td>\n",
       "      <td>0.503117</td>\n",
       "      <td>0.496402</td>\n",
       "      <td>0.960279</td>\n",
       "      <td>00:02:01.234849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.885953</td>\n",
       "      <td>0.866257</td>\n",
       "      <td>0.869579</td>\n",
       "      <td>0.980332</td>\n",
       "      <td>0.503322</td>\n",
       "      <td>0.496569</td>\n",
       "      <td>0.960673</td>\n",
       "      <td>00:02:01.870318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.889282</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.480195</td>\n",
       "      <td>0.499795</td>\n",
       "      <td>0.489799</td>\n",
       "      <td>0.960011</td>\n",
       "      <td>00:02:01.766925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.888785</td>\n",
       "      <td>0.842569</td>\n",
       "      <td>0.842569</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>0.489867</td>\n",
       "      <td>0.960274</td>\n",
       "      <td>00:02:01.132004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.889708</td>\n",
       "      <td>0.825224</td>\n",
       "      <td>0.825224</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>0.489867</td>\n",
       "      <td>0.960274</td>\n",
       "      <td>00:02:02.272340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.890410</td>\n",
       "      <td>0.845171</td>\n",
       "      <td>0.845171</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.499932</td>\n",
       "      <td>0.489867</td>\n",
       "      <td>0.960274</td>\n",
       "      <td>00:02:03.566950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.889260</td>\n",
       "      <td>0.835608</td>\n",
       "      <td>0.835608</td>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.501593</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.960405</td>\n",
       "      <td>00:02:01.467451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.889576</td>\n",
       "      <td>0.828226</td>\n",
       "      <td>0.828226</td>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.501593</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.960405</td>\n",
       "      <td>00:02:01.917071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.889679</td>\n",
       "      <td>0.828749</td>\n",
       "      <td>0.832082</td>\n",
       "      <td>0.730326</td>\n",
       "      <td>0.501598</td>\n",
       "      <td>0.493244</td>\n",
       "      <td>0.960532</td>\n",
       "      <td>00:02:01.472406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.888830</td>\n",
       "      <td>0.847726</td>\n",
       "      <td>0.847726</td>\n",
       "      <td>0.813723</td>\n",
       "      <td>0.503265</td>\n",
       "      <td>0.496566</td>\n",
       "      <td>0.960663</td>\n",
       "      <td>00:02:01.331720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.889232</td>\n",
       "      <td>0.839568</td>\n",
       "      <td>0.840565</td>\n",
       "      <td>0.658603</td>\n",
       "      <td>0.501408</td>\n",
       "      <td>0.492858</td>\n",
       "      <td>0.960379</td>\n",
       "      <td>00:02:01.803203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.164551</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>00:00:00.675845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.890837  0.832903  0.836225   0.680324  0.503117  0.496402   \n",
       "KF_2      0.885953  0.866257  0.869579   0.980332  0.503322  0.496569   \n",
       "KF_3      0.889282  0.843243  0.843243   0.480195  0.499795  0.489799   \n",
       "KF_4      0.888785  0.842569  0.842569   0.480200  0.499932  0.489867   \n",
       "KF_5      0.889708  0.825224  0.825224   0.480200  0.499932  0.489867   \n",
       "KF_6      0.890410  0.845171  0.845171   0.480200  0.499932  0.489867   \n",
       "KF_7      0.889260  0.835608  0.835608   0.730263  0.501593  0.493200   \n",
       "KF_8      0.889576  0.828226  0.828226   0.730263  0.501593  0.493200   \n",
       "KF_9      0.889679  0.828749  0.832082   0.730326  0.501598  0.493244   \n",
       "KF_10     0.888830  0.847726  0.847726   0.813723  0.503265  0.496566   \n",
       "Media     0.889232  0.839568  0.840565   0.658603  0.501408  0.492858   \n",
       "STD       0.001250  0.011594  0.011952   0.164551  0.001389  0.002769   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.960279 00:02:01.234849  \n",
       "KF_2   0.960673 00:02:01.870318  \n",
       "KF_3   0.960011 00:02:01.766925  \n",
       "KF_4   0.960274 00:02:01.132004  \n",
       "KF_5   0.960274 00:02:02.272340  \n",
       "KF_6   0.960274 00:02:03.566950  \n",
       "KF_7   0.960405 00:02:01.467451  \n",
       "KF_8   0.960405 00:02:01.917071  \n",
       "KF_9   0.960532 00:02:01.472406  \n",
       "KF_10  0.960663 00:02:01.331720  \n",
       "Media  0.960379 00:02:01.803203  \n",
       "STD    0.000193 00:00:00.675845  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'XGBoost'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i+'            ', end=\"\\r\")\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = XGBClassifier(\n",
    "                          learning_rate = 0.03,\n",
    "                          n_estimators = 350, \n",
    "                          objective = 'reg:logistic',\n",
    "                          max_depth = 5,\n",
    "                          subsample = 0.75,\n",
    "                          colsample_bytree=0.7\n",
    "                        )\n",
    "    model.fit(x_train, y_train)\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train, model.predict_proba(x_train)[:,1])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred_proba)\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "\n",
    "print()\n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()\n",
    "    \n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF_1\n",
      "Train on 97447 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97447/97447 [==============================] - 13s - loss: 0.4624 - acc: 0.7970 - val_loss: 0.4315 - val_acc: 0.8055\n",
      "Epoch 2/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.3977 - acc: 0.8367 - val_loss: 0.3523 - val_acc: 0.8556\n",
      "Epoch 3/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.3610 - acc: 0.8527 - val_loss: 0.3868 - val_acc: 0.8470\n",
      "Epoch 4/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.3360 - acc: 0.8631 - val_loss: 0.3596 - val_acc: 0.8482\n",
      "Epoch 5/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.3206 - acc: 0.8700 - val_loss: 0.3660 - val_acc: 0.8440\n",
      "Epoch 6/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.3098 - acc: 0.8740 - val_loss: 0.3379 - val_acc: 0.8641\n",
      "Epoch 7/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.3002 - acc: 0.8789 - val_loss: 0.3532 - val_acc: 0.8574\n",
      "Epoch 8/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2929 - acc: 0.8824 - val_loss: 0.3760 - val_acc: 0.8579\n",
      "Epoch 9/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2865 - acc: 0.8852 - val_loss: 0.3145 - val_acc: 0.8654\n",
      "Epoch 10/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2815 - acc: 0.8871 - val_loss: 0.4009 - val_acc: 0.8597\n",
      "Epoch 11/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2775 - acc: 0.8892 - val_loss: 0.3345 - val_acc: 0.8597\n",
      "Epoch 12/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2725 - acc: 0.8912 - val_loss: 0.3105 - val_acc: 0.8734\n",
      "Epoch 13/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2690 - acc: 0.8932 - val_loss: 0.3960 - val_acc: 0.8302\n",
      "Epoch 14/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2657 - acc: 0.8941 - val_loss: 0.3414 - val_acc: 0.8600\n",
      "Epoch 15/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2627 - acc: 0.8959 - val_loss: 0.4049 - val_acc: 0.8527\n",
      "Epoch 16/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2597 - acc: 0.8958 - val_loss: 0.3315 - val_acc: 0.8663\n",
      "Epoch 17/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2571 - acc: 0.8981 - val_loss: 0.3410 - val_acc: 0.8584\n",
      "Epoch 18/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2551 - acc: 0.8993 - val_loss: 0.3653 - val_acc: 0.8598\n",
      "Epoch 19/10000\n",
      "97447/97447 [==============================] - 7s - loss: 0.2537 - acc: 0.8998 - val_loss: 0.2990 - val_acc: 0.8726\n",
      "Epoch 20/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2509 - acc: 0.9014 - val_loss: 0.2902 - val_acc: 0.8734\n",
      "Epoch 21/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2489 - acc: 0.9023 - val_loss: 0.2991 - val_acc: 0.8694\n",
      "Epoch 22/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2480 - acc: 0.9027 - val_loss: 0.3152 - val_acc: 0.8639\n",
      "Epoch 23/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2466 - acc: 0.9029 - val_loss: 0.2965 - val_acc: 0.8622\n",
      "Epoch 24/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2442 - acc: 0.9046 - val_loss: 0.2591 - val_acc: 0.8850\n",
      "Epoch 25/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2430 - acc: 0.9042 - val_loss: 0.3370 - val_acc: 0.8590\n",
      "Epoch 26/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2406 - acc: 0.9053 - val_loss: 0.2700 - val_acc: 0.8779\n",
      "Epoch 27/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2396 - acc: 0.9064 - val_loss: 0.3634 - val_acc: 0.8593\n",
      "Epoch 28/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2383 - acc: 0.9067 - val_loss: 0.2925 - val_acc: 0.8779\n",
      "Epoch 29/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2367 - acc: 0.9079 - val_loss: 0.3165 - val_acc: 0.8685\n",
      "Epoch 30/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2362 - acc: 0.9080 - val_loss: 0.2802 - val_acc: 0.8780\n",
      "Epoch 31/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2351 - acc: 0.9080 - val_loss: 0.2920 - val_acc: 0.8724\n",
      "Epoch 32/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2340 - acc: 0.9096 - val_loss: 0.3295 - val_acc: 0.8655\n",
      "Epoch 33/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2318 - acc: 0.9090 - val_loss: 0.2914 - val_acc: 0.8728\n",
      "Epoch 34/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2311 - acc: 0.9093 - val_loss: 0.3119 - val_acc: 0.8664\n",
      "Epoch 35/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2302 - acc: 0.9106 - val_loss: 0.3210 - val_acc: 0.8684\n",
      "Epoch 36/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2287 - acc: 0.9111 - val_loss: 0.3666 - val_acc: 0.8598\n",
      "Epoch 37/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2283 - acc: 0.9115 - val_loss: 0.3000 - val_acc: 0.8720\n",
      "Epoch 38/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2274 - acc: 0.9118 - val_loss: 0.3149 - val_acc: 0.8702\n",
      "Epoch 39/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2258 - acc: 0.9120 - val_loss: 0.3404 - val_acc: 0.8700\n",
      "Epoch 40/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2249 - acc: 0.9135 - val_loss: 0.2838 - val_acc: 0.8787\n",
      "Epoch 41/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2243 - acc: 0.9134 - val_loss: 0.3152 - val_acc: 0.8725\n",
      "Epoch 42/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2237 - acc: 0.9134 - val_loss: 0.2955 - val_acc: 0.8740\n",
      "Epoch 43/10000\n",
      "97447/97447 [==============================] - 7s - loss: 0.2221 - acc: 0.9141 - val_loss: 0.3642 - val_acc: 0.8547\n",
      "Epoch 44/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2214 - acc: 0.9146 - val_loss: 0.3093 - val_acc: 0.8718\n",
      "Epoch 45/10000\n",
      "97447/97447 [==============================] - 6s - loss: 0.2208 - acc: 0.9149 - val_loss: 0.3364 - val_acc: 0.8667\n",
      "97447/97447 [==============================] - 7s     \n",
      "KF_2\n",
      "Train on 97548 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.4620 - acc: 0.7927 - val_loss: 0.4747 - val_acc: 0.7594\n",
      "Epoch 2/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3977 - acc: 0.8324 - val_loss: 0.4261 - val_acc: 0.8092\n",
      "Epoch 3/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3652 - acc: 0.8490 - val_loss: 0.3511 - val_acc: 0.8518\n",
      "Epoch 4/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3446 - acc: 0.8560 - val_loss: 0.4285 - val_acc: 0.8262\n",
      "Epoch 5/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3288 - acc: 0.8635 - val_loss: 0.3586 - val_acc: 0.8503\n",
      "Epoch 6/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3162 - acc: 0.8695 - val_loss: 0.3422 - val_acc: 0.8503\n",
      "Epoch 7/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3069 - acc: 0.8735 - val_loss: 0.3860 - val_acc: 0.8481\n",
      "Epoch 8/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.3000 - acc: 0.8770 - val_loss: 0.4137 - val_acc: 0.8361\n",
      "Epoch 9/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2932 - acc: 0.8794 - val_loss: 0.3261 - val_acc: 0.8606\n",
      "Epoch 10/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2879 - acc: 0.8809 - val_loss: 0.3653 - val_acc: 0.8411\n",
      "Epoch 11/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2835 - acc: 0.8842 - val_loss: 0.2904 - val_acc: 0.8610\n",
      "Epoch 12/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2786 - acc: 0.8853 - val_loss: 0.4141 - val_acc: 0.8423\n",
      "Epoch 13/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2753 - acc: 0.8887 - val_loss: 0.3349 - val_acc: 0.8582\n",
      "Epoch 14/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2719 - acc: 0.8893 - val_loss: 0.3278 - val_acc: 0.8652\n",
      "Epoch 15/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2688 - acc: 0.8904 - val_loss: 0.4640 - val_acc: 0.8150\n",
      "Epoch 16/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2660 - acc: 0.8914 - val_loss: 0.3396 - val_acc: 0.8572\n",
      "Epoch 17/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97548/97548 [==============================] - 5s - loss: 0.2637 - acc: 0.8921 - val_loss: 0.2359 - val_acc: 0.8940\n",
      "Epoch 18/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2609 - acc: 0.8949 - val_loss: 0.3366 - val_acc: 0.8568\n",
      "Epoch 19/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2589 - acc: 0.8954 - val_loss: 0.2616 - val_acc: 0.8827\n",
      "Epoch 20/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2564 - acc: 0.8961 - val_loss: 0.2980 - val_acc: 0.8710\n",
      "Epoch 21/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2545 - acc: 0.8980 - val_loss: 0.3911 - val_acc: 0.8434\n",
      "Epoch 22/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2514 - acc: 0.8986 - val_loss: 0.3457 - val_acc: 0.8579\n",
      "Epoch 23/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2500 - acc: 0.8997 - val_loss: 0.2981 - val_acc: 0.8738\n",
      "Epoch 24/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2482 - acc: 0.9002 - val_loss: 0.2841 - val_acc: 0.8723\n",
      "Epoch 25/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2464 - acc: 0.9006 - val_loss: 0.2525 - val_acc: 0.8884\n",
      "Epoch 26/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2452 - acc: 0.9018 - val_loss: 0.3717 - val_acc: 0.8519\n",
      "Epoch 27/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2434 - acc: 0.9030 - val_loss: 0.2859 - val_acc: 0.8718\n",
      "Epoch 28/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2420 - acc: 0.9029 - val_loss: 0.2776 - val_acc: 0.8796\n",
      "Epoch 29/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2409 - acc: 0.9036 - val_loss: 0.3393 - val_acc: 0.8668\n",
      "Epoch 30/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2398 - acc: 0.9038 - val_loss: 0.3421 - val_acc: 0.8550\n",
      "Epoch 31/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2377 - acc: 0.9050 - val_loss: 0.4118 - val_acc: 0.8378\n",
      "Epoch 32/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2373 - acc: 0.9055 - val_loss: 0.3327 - val_acc: 0.8651\n",
      "Epoch 33/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2355 - acc: 0.9065 - val_loss: 0.2823 - val_acc: 0.8794\n",
      "Epoch 34/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2350 - acc: 0.9064 - val_loss: 0.3663 - val_acc: 0.8508\n",
      "Epoch 35/10000\n",
      "97548/97548 [==============================] - 6s - loss: 0.2328 - acc: 0.9070 - val_loss: 0.2818 - val_acc: 0.8761\n",
      "Epoch 36/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2316 - acc: 0.9081 - val_loss: 0.3374 - val_acc: 0.8384\n",
      "Epoch 37/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2311 - acc: 0.9087 - val_loss: 0.4377 - val_acc: 0.8346\n",
      "Epoch 38/10000\n",
      "97548/97548 [==============================] - 5s - loss: 0.2301 - acc: 0.9083 - val_loss: 0.4314 - val_acc: 0.8443\n",
      "97248/97548 [============================>.] - ETA:  - ETA: 0sKF_3\n",
      "Train on 97662 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97662/97662 [==============================] - 6s - loss: 0.4594 - acc: 0.7958 - val_loss: 0.4270 - val_acc: 0.8123\n",
      "Epoch 2/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.3918 - acc: 0.8375 - val_loss: 0.3151 - val_acc: 0.8568\n",
      "Epoch 3/10000\n",
      "97662/97662 [==============================] - 6s - loss: 0.3521 - acc: 0.8552 - val_loss: 0.3697 - val_acc: 0.8425\n",
      "Epoch 4/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.3310 - acc: 0.8626 - val_loss: 0.3664 - val_acc: 0.8449\n",
      "Epoch 5/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.3192 - acc: 0.8674 - val_loss: 0.2860 - val_acc: 0.8721\n",
      "Epoch 6/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.3069 - acc: 0.8722 - val_loss: 0.3785 - val_acc: 0.8457\n",
      "Epoch 7/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2992 - acc: 0.8755 - val_loss: 0.3044 - val_acc: 0.8555\n",
      "Epoch 8/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2927 - acc: 0.8797 - val_loss: 0.3213 - val_acc: 0.8503\n",
      "Epoch 9/10000\n",
      "97662/97662 [==============================] - 6s - loss: 0.2858 - acc: 0.8820 - val_loss: 0.3574 - val_acc: 0.8264\n",
      "Epoch 10/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2812 - acc: 0.8840 - val_loss: 0.3737 - val_acc: 0.8397\n",
      "Epoch 11/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2769 - acc: 0.8866 - val_loss: 0.2495 - val_acc: 0.8928\n",
      "Epoch 12/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2729 - acc: 0.8888 - val_loss: 0.2692 - val_acc: 0.8759\n",
      "Epoch 13/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2691 - acc: 0.8905 - val_loss: 0.3579 - val_acc: 0.8410\n",
      "Epoch 14/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2671 - acc: 0.8910 - val_loss: 0.3305 - val_acc: 0.8594\n",
      "Epoch 15/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2633 - acc: 0.8937 - val_loss: 0.3934 - val_acc: 0.8367\n",
      "Epoch 16/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2607 - acc: 0.8940 - val_loss: 0.3210 - val_acc: 0.8670\n",
      "Epoch 17/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2572 - acc: 0.8960 - val_loss: 0.3342 - val_acc: 0.8588\n",
      "Epoch 18/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2553 - acc: 0.8964 - val_loss: 0.2785 - val_acc: 0.8744\n",
      "Epoch 19/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2538 - acc: 0.8961 - val_loss: 0.3501 - val_acc: 0.8535\n",
      "Epoch 20/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2504 - acc: 0.8994 - val_loss: 0.3728 - val_acc: 0.8399\n",
      "Epoch 21/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2486 - acc: 0.8990 - val_loss: 0.2428 - val_acc: 0.8973\n",
      "Epoch 22/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2481 - acc: 0.8991 - val_loss: 0.2734 - val_acc: 0.8780\n",
      "Epoch 23/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2457 - acc: 0.9014 - val_loss: 0.2688 - val_acc: 0.8840\n",
      "Epoch 24/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2448 - acc: 0.9024 - val_loss: 0.3459 - val_acc: 0.8595\n",
      "Epoch 25/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2432 - acc: 0.9024 - val_loss: 0.3088 - val_acc: 0.8643\n",
      "Epoch 26/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2411 - acc: 0.9023 - val_loss: 0.3550 - val_acc: 0.8544\n",
      "Epoch 27/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2399 - acc: 0.9035 - val_loss: 0.2455 - val_acc: 0.9021\n",
      "Epoch 28/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2393 - acc: 0.9041 - val_loss: 0.3326 - val_acc: 0.8600\n",
      "Epoch 29/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2385 - acc: 0.9041 - val_loss: 0.4220 - val_acc: 0.8447\n",
      "Epoch 30/10000\n",
      "97662/97662 [==============================] - 6s - loss: 0.2362 - acc: 0.9062 - val_loss: 0.3034 - val_acc: 0.8827\n",
      "Epoch 31/10000\n",
      "97662/97662 [==============================] - 6s - loss: 0.2352 - acc: 0.9065 - val_loss: 0.3057 - val_acc: 0.8607\n",
      "Epoch 32/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2331 - acc: 0.9076 - val_loss: 0.5000 - val_acc: 0.8394\n",
      "Epoch 33/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2328 - acc: 0.9071 - val_loss: 0.3771 - val_acc: 0.8511\n",
      "Epoch 34/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2314 - acc: 0.9089 - val_loss: 0.2907 - val_acc: 0.8644\n",
      "Epoch 35/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2309 - acc: 0.9086 - val_loss: 0.2967 - val_acc: 0.8711\n",
      "Epoch 36/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2303 - acc: 0.9093 - val_loss: 0.3604 - val_acc: 0.8541\n",
      "Epoch 37/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2278 - acc: 0.9097 - val_loss: 0.3710 - val_acc: 0.8593\n",
      "Epoch 38/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2268 - acc: 0.9110 - val_loss: 0.3074 - val_acc: 0.8645\n",
      "Epoch 39/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2259 - acc: 0.9105 - val_loss: 0.2978 - val_acc: 0.8721\n",
      "Epoch 40/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97662/97662 [==============================] - 5s - loss: 0.2261 - acc: 0.9112 - val_loss: 0.2613 - val_acc: 0.9047\n",
      "Epoch 41/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2262 - acc: 0.9111 - val_loss: 0.2738 - val_acc: 0.8883\n",
      "Epoch 42/10000\n",
      "97662/97662 [==============================] - 5s - loss: 0.2235 - acc: 0.9124 - val_loss: 0.4399 - val_acc: 0.8327\n",
      "97312/97662 [============================>.] - ETA: 0sKF_4\n",
      "Train on 97478 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.4612 - acc: 0.7949 - val_loss: 0.4937 - val_acc: 0.7657\n",
      "Epoch 2/10000\n",
      "97478/97478 [==============================] - 5s - loss: 0.3939 - acc: 0.8375 - val_loss: 0.3789 - val_acc: 0.8467\n",
      "Epoch 3/10000\n",
      "97478/97478 [==============================] - 5s - loss: 0.3601 - acc: 0.8524 - val_loss: 0.3655 - val_acc: 0.8506\n",
      "Epoch 4/10000\n",
      "97478/97478 [==============================] - 5s - loss: 0.3405 - acc: 0.8606 - val_loss: 0.4060 - val_acc: 0.8346\n",
      "Epoch 5/10000\n",
      "97478/97478 [==============================] - 5s - loss: 0.3232 - acc: 0.8672 - val_loss: 0.3292 - val_acc: 0.8574\n",
      "Epoch 6/10000\n",
      "97478/97478 [==============================] - 5s - loss: 0.3138 - acc: 0.8716 - val_loss: 0.3593 - val_acc: 0.8424\n",
      "Epoch 7/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.3046 - acc: 0.8757 - val_loss: 0.3747 - val_acc: 0.8504\n",
      "Epoch 8/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2983 - acc: 0.8785 - val_loss: 0.3806 - val_acc: 0.8482\n",
      "Epoch 9/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2912 - acc: 0.8824 - val_loss: 0.3976 - val_acc: 0.8335\n",
      "Epoch 10/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2867 - acc: 0.8846 - val_loss: 0.3383 - val_acc: 0.8581\n",
      "Epoch 11/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2823 - acc: 0.8874 - val_loss: 0.3691 - val_acc: 0.8543\n",
      "Epoch 12/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2789 - acc: 0.8876 - val_loss: 0.3267 - val_acc: 0.8636\n",
      "Epoch 13/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2763 - acc: 0.8899 - val_loss: 0.3724 - val_acc: 0.8534\n",
      "Epoch 14/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2720 - acc: 0.8914 - val_loss: 0.3474 - val_acc: 0.8597\n",
      "Epoch 15/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2693 - acc: 0.8929 - val_loss: 0.4057 - val_acc: 0.8322\n",
      "Epoch 16/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2666 - acc: 0.8938 - val_loss: 0.3705 - val_acc: 0.8414\n",
      "Epoch 17/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2631 - acc: 0.8948 - val_loss: 0.3505 - val_acc: 0.8555\n",
      "Epoch 18/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2613 - acc: 0.8967 - val_loss: 0.4250 - val_acc: 0.8300\n",
      "Epoch 19/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2575 - acc: 0.8980 - val_loss: 0.3308 - val_acc: 0.8607\n",
      "Epoch 20/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2546 - acc: 0.8986 - val_loss: 0.3838 - val_acc: 0.8432\n",
      "Epoch 21/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2528 - acc: 0.8997 - val_loss: 0.3396 - val_acc: 0.8558\n",
      "Epoch 22/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2503 - acc: 0.9002 - val_loss: 0.3674 - val_acc: 0.8582\n",
      "Epoch 23/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2494 - acc: 0.9019 - val_loss: 0.3195 - val_acc: 0.8620\n",
      "Epoch 24/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2465 - acc: 0.9022 - val_loss: 0.3088 - val_acc: 0.8678\n",
      "Epoch 25/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2440 - acc: 0.9037 - val_loss: 0.3008 - val_acc: 0.8728\n",
      "Epoch 26/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2434 - acc: 0.9044 - val_loss: 0.3106 - val_acc: 0.8654\n",
      "Epoch 27/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2409 - acc: 0.9054 - val_loss: 0.3243 - val_acc: 0.8718\n",
      "Epoch 28/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2398 - acc: 0.9056 - val_loss: 0.2791 - val_acc: 0.8764\n",
      "Epoch 29/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2380 - acc: 0.9060 - val_loss: 0.3604 - val_acc: 0.8496\n",
      "Epoch 30/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2369 - acc: 0.9077 - val_loss: 0.3125 - val_acc: 0.8720\n",
      "Epoch 31/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2349 - acc: 0.9080 - val_loss: 0.3290 - val_acc: 0.8636\n",
      "Epoch 32/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2337 - acc: 0.9080 - val_loss: 0.3534 - val_acc: 0.8578\n",
      "Epoch 33/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2327 - acc: 0.9090 - val_loss: 0.3281 - val_acc: 0.8635\n",
      "Epoch 34/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2311 - acc: 0.9091 - val_loss: 0.3004 - val_acc: 0.8722\n",
      "Epoch 35/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2299 - acc: 0.9099 - val_loss: 0.2611 - val_acc: 0.8911\n",
      "Epoch 36/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2294 - acc: 0.9103 - val_loss: 0.3471 - val_acc: 0.8665\n",
      "Epoch 37/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2276 - acc: 0.9116 - val_loss: 0.3731 - val_acc: 0.8609\n",
      "Epoch 38/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2267 - acc: 0.9107 - val_loss: 0.2748 - val_acc: 0.8789\n",
      "Epoch 39/10000\n",
      "97478/97478 [==============================] - 7s - loss: 0.2260 - acc: 0.9116 - val_loss: 0.3770 - val_acc: 0.8524\n",
      "Epoch 40/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2241 - acc: 0.9120 - val_loss: 0.3822 - val_acc: 0.8565\n",
      "Epoch 41/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2227 - acc: 0.9132 - val_loss: 0.3253 - val_acc: 0.8720\n",
      "Epoch 42/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2235 - acc: 0.9130 - val_loss: 0.3373 - val_acc: 0.8701\n",
      "Epoch 43/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2215 - acc: 0.9132 - val_loss: 0.2937 - val_acc: 0.8782\n",
      "Epoch 44/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2214 - acc: 0.9137 - val_loss: 0.3342 - val_acc: 0.8658\n",
      "Epoch 45/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2197 - acc: 0.9151 - val_loss: 0.3337 - val_acc: 0.8645\n",
      "Epoch 46/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2190 - acc: 0.9143 - val_loss: 0.3508 - val_acc: 0.8612\n",
      "Epoch 47/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2185 - acc: 0.9150 - val_loss: 0.3153 - val_acc: 0.8703\n",
      "Epoch 48/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2175 - acc: 0.9162 - val_loss: 0.2957 - val_acc: 0.8785\n",
      "Epoch 49/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2162 - acc: 0.9163 - val_loss: 0.3097 - val_acc: 0.8770\n",
      "Epoch 50/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2160 - acc: 0.9164 - val_loss: 0.3072 - val_acc: 0.8733\n",
      "Epoch 51/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2146 - acc: 0.9165 - val_loss: 0.2996 - val_acc: 0.8810\n",
      "Epoch 52/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2143 - acc: 0.9167 - val_loss: 0.3472 - val_acc: 0.8620\n",
      "Epoch 53/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2138 - acc: 0.9175 - val_loss: 0.2770 - val_acc: 0.8821\n",
      "Epoch 54/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2120 - acc: 0.9186 - val_loss: 0.3322 - val_acc: 0.8707\n",
      "Epoch 55/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2130 - acc: 0.9172 - val_loss: 0.2952 - val_acc: 0.8794\n",
      "Epoch 56/10000\n",
      "97478/97478 [==============================] - 6s - loss: 0.2114 - acc: 0.9168 - val_loss: 0.3567 - val_acc: 0.8597\n",
      "97478/97478 [==============================] - 8s     \n",
      "KF_5\n",
      "Train on 97502 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97502/97502 [==============================] - 6s - loss: 0.4632 - acc: 0.7936 - val_loss: 0.4684 - val_acc: 0.7979\n",
      "Epoch 2/10000\n",
      "97502/97502 [==============================] - 6s - loss: 0.4006 - acc: 0.8333 - val_loss: 0.3801 - val_acc: 0.8348\n",
      "Epoch 3/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97502/97502 [==============================] - 5s - loss: 0.3673 - acc: 0.8465 - val_loss: 0.4560 - val_acc: 0.8042\n",
      "Epoch 4/10000\n",
      "97502/97502 [==============================] - 6s - loss: 0.3481 - acc: 0.8543 - val_loss: 0.3781 - val_acc: 0.8270\n",
      "Epoch 5/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.3318 - acc: 0.8601 - val_loss: 0.3868 - val_acc: 0.8471\n",
      "Epoch 6/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.3203 - acc: 0.8647 - val_loss: 0.3567 - val_acc: 0.8489\n",
      "Epoch 7/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.3102 - acc: 0.8690 - val_loss: 0.2912 - val_acc: 0.8867\n",
      "Epoch 8/10000\n",
      "97502/97502 [==============================] - 6s - loss: 0.3049 - acc: 0.8733 - val_loss: 0.7168 - val_acc: 0.7511\n",
      "Epoch 9/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.3000 - acc: 0.8752 - val_loss: 0.3375 - val_acc: 0.8661\n",
      "Epoch 10/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2913 - acc: 0.8796 - val_loss: 0.3373 - val_acc: 0.8612\n",
      "Epoch 11/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2869 - acc: 0.8818 - val_loss: 0.3211 - val_acc: 0.8669\n",
      "Epoch 12/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2826 - acc: 0.8836 - val_loss: 0.3800 - val_acc: 0.8275\n",
      "Epoch 13/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2790 - acc: 0.8857 - val_loss: 0.3625 - val_acc: 0.8538\n",
      "Epoch 14/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2749 - acc: 0.8866 - val_loss: 0.5000 - val_acc: 0.8239\n",
      "Epoch 15/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2722 - acc: 0.8885 - val_loss: 0.4041 - val_acc: 0.8403\n",
      "Epoch 16/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2690 - acc: 0.8898 - val_loss: 0.3311 - val_acc: 0.8447\n",
      "Epoch 17/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2656 - acc: 0.8925 - val_loss: 0.3531 - val_acc: 0.8459\n",
      "Epoch 18/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2636 - acc: 0.8921 - val_loss: 0.4153 - val_acc: 0.8422\n",
      "Epoch 19/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2670 - acc: 0.8917 - val_loss: 0.5302 - val_acc: 0.8107\n",
      "Epoch 20/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2588 - acc: 0.8956 - val_loss: 0.3101 - val_acc: 0.9096\n",
      "Epoch 21/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2702 - acc: 0.8919 - val_loss: 0.2924 - val_acc: 0.8731\n",
      "Epoch 22/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2542 - acc: 0.8972 - val_loss: 0.2638 - val_acc: 0.8908\n",
      "Epoch 23/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2536 - acc: 0.8982 - val_loss: 0.2955 - val_acc: 0.9053\n",
      "Epoch 24/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2572 - acc: 0.8971 - val_loss: 0.4956 - val_acc: 0.8085\n",
      "Epoch 25/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2497 - acc: 0.9001 - val_loss: 0.3968 - val_acc: 0.8434\n",
      "Epoch 26/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2467 - acc: 0.9015 - val_loss: 0.3240 - val_acc: 0.8490\n",
      "Epoch 27/10000\n",
      "97502/97502 [==============================] - 6s - loss: 0.2447 - acc: 0.9015 - val_loss: 0.6025 - val_acc: 0.8015\n",
      "Epoch 28/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2432 - acc: 0.9026 - val_loss: 0.9386 - val_acc: 0.7366\n",
      "Epoch 29/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2438 - acc: 0.9033 - val_loss: 0.3291 - val_acc: 0.8655\n",
      "Epoch 30/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2392 - acc: 0.9049 - val_loss: 0.3123 - val_acc: 0.8726\n",
      "Epoch 31/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2393 - acc: 0.9045 - val_loss: 0.3926 - val_acc: 0.8481\n",
      "Epoch 32/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2387 - acc: 0.9048 - val_loss: 0.3517 - val_acc: 0.8391\n",
      "Epoch 33/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2360 - acc: 0.9067 - val_loss: 0.7922 - val_acc: 0.7387\n",
      "Epoch 34/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2366 - acc: 0.9065 - val_loss: 0.5084 - val_acc: 0.7934\n",
      "Epoch 35/10000\n",
      "97502/97502 [==============================] - 6s - loss: 0.2450 - acc: 0.9026 - val_loss: 0.3132 - val_acc: 0.8655\n",
      "Epoch 36/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2336 - acc: 0.9078 - val_loss: 0.3518 - val_acc: 0.8516\n",
      "Epoch 37/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2316 - acc: 0.9088 - val_loss: 0.3307 - val_acc: 0.8682\n",
      "Epoch 38/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2303 - acc: 0.9086 - val_loss: 0.4766 - val_acc: 0.8267\n",
      "Epoch 39/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2292 - acc: 0.9099 - val_loss: 0.3866 - val_acc: 0.8508\n",
      "Epoch 40/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2277 - acc: 0.9104 - val_loss: 0.2885 - val_acc: 0.8715\n",
      "Epoch 41/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2268 - acc: 0.9105 - val_loss: 0.3571 - val_acc: 0.8625\n",
      "Epoch 42/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2268 - acc: 0.9099 - val_loss: 0.3819 - val_acc: 0.8568\n",
      "Epoch 43/10000\n",
      "97502/97502 [==============================] - 5s - loss: 0.2248 - acc: 0.9119 - val_loss: 0.4324 - val_acc: 0.8315\n",
      "97408/97502 [============================>.] - ETA: 0sKF_6\n",
      "Train on 97427 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.4635 - acc: 0.7927 - val_loss: 0.4949 - val_acc: 0.7374\n",
      "Epoch 2/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.4001 - acc: 0.8334 - val_loss: 0.3681 - val_acc: 0.8404\n",
      "Epoch 3/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.3632 - acc: 0.8493 - val_loss: 0.3712 - val_acc: 0.8437\n",
      "Epoch 4/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.3401 - acc: 0.8608 - val_loss: 0.3593 - val_acc: 0.8506\n",
      "Epoch 5/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.3246 - acc: 0.8669 - val_loss: 0.3391 - val_acc: 0.8561\n",
      "Epoch 6/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.3130 - acc: 0.8722 - val_loss: 0.3674 - val_acc: 0.8462\n",
      "Epoch 7/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.3026 - acc: 0.8771 - val_loss: 0.2982 - val_acc: 0.8692\n",
      "Epoch 8/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2945 - acc: 0.8803 - val_loss: 0.3257 - val_acc: 0.8574\n",
      "Epoch 9/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2891 - acc: 0.8829 - val_loss: 0.3570 - val_acc: 0.8564\n",
      "Epoch 10/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2843 - acc: 0.8859 - val_loss: 0.3459 - val_acc: 0.8560\n",
      "Epoch 11/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2784 - acc: 0.8888 - val_loss: 0.3213 - val_acc: 0.8603\n",
      "Epoch 12/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2748 - acc: 0.8895 - val_loss: 0.3110 - val_acc: 0.8635\n",
      "Epoch 13/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2704 - acc: 0.8919 - val_loss: 0.2770 - val_acc: 0.8730\n",
      "Epoch 14/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2671 - acc: 0.8933 - val_loss: 0.4135 - val_acc: 0.8284\n",
      "Epoch 15/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2630 - acc: 0.8945 - val_loss: 0.3717 - val_acc: 0.8456\n",
      "Epoch 16/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2599 - acc: 0.8972 - val_loss: 0.3528 - val_acc: 0.8602\n",
      "Epoch 17/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2569 - acc: 0.8971 - val_loss: 0.3299 - val_acc: 0.8558\n",
      "Epoch 18/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2544 - acc: 0.8987 - val_loss: 0.2797 - val_acc: 0.8764\n",
      "Epoch 19/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2514 - acc: 0.9000 - val_loss: 0.3737 - val_acc: 0.8337\n",
      "Epoch 20/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2495 - acc: 0.9012 - val_loss: 0.3266 - val_acc: 0.8680\n",
      "Epoch 21/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97427/97427 [==============================] - 5s - loss: 0.2472 - acc: 0.9019 - val_loss: 0.2777 - val_acc: 0.8757\n",
      "Epoch 22/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2453 - acc: 0.9026 - val_loss: 0.3219 - val_acc: 0.8677\n",
      "Epoch 23/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2427 - acc: 0.9046 - val_loss: 0.3514 - val_acc: 0.8574\n",
      "Epoch 24/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2409 - acc: 0.9056 - val_loss: 0.3874 - val_acc: 0.8564\n",
      "Epoch 25/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2399 - acc: 0.9052 - val_loss: 0.3462 - val_acc: 0.8563\n",
      "Epoch 26/10000\n",
      "97427/97427 [==============================] - 5s - loss: 0.2376 - acc: 0.9070 - val_loss: 0.3122 - val_acc: 0.8656\n",
      "Epoch 27/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2365 - acc: 0.9079 - val_loss: 0.3298 - val_acc: 0.8635\n",
      "Epoch 28/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2337 - acc: 0.9091 - val_loss: 0.2971 - val_acc: 0.8652\n",
      "Epoch 29/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2314 - acc: 0.9095 - val_loss: 0.3191 - val_acc: 0.8745\n",
      "Epoch 30/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2309 - acc: 0.9108 - val_loss: 0.3075 - val_acc: 0.8712\n",
      "Epoch 31/10000\n",
      "97427/97427 [==============================] - 7s - loss: 0.2301 - acc: 0.9101 - val_loss: 0.3911 - val_acc: 0.8519\n",
      "Epoch 32/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2271 - acc: 0.9121 - val_loss: 0.3341 - val_acc: 0.8677\n",
      "Epoch 33/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2268 - acc: 0.9124 - val_loss: 0.3596 - val_acc: 0.8607\n",
      "Epoch 34/10000\n",
      "97427/97427 [==============================] - 6s - loss: 0.2254 - acc: 0.9128 - val_loss: 0.4010 - val_acc: 0.8505\n",
      "97376/97427 [============================>.] - ETA: 0sKF_7\n",
      "Train on 97561 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.4618 - acc: 0.7941 - val_loss: 0.4466 - val_acc: 0.7898\n",
      "Epoch 2/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.3905 - acc: 0.8385 - val_loss: 0.4827 - val_acc: 0.7779\n",
      "Epoch 3/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.3557 - acc: 0.8533 - val_loss: 0.4103 - val_acc: 0.8305\n",
      "Epoch 4/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.3327 - acc: 0.8624 - val_loss: 0.3398 - val_acc: 0.8567\n",
      "Epoch 5/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.3175 - acc: 0.8697 - val_loss: 0.3110 - val_acc: 0.8635\n",
      "Epoch 6/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.3072 - acc: 0.8748 - val_loss: 0.2961 - val_acc: 0.8676\n",
      "Epoch 7/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.2972 - acc: 0.8782 - val_loss: 0.2909 - val_acc: 0.8652\n",
      "Epoch 8/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2907 - acc: 0.8817 - val_loss: 0.3326 - val_acc: 0.8606\n",
      "Epoch 9/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2854 - acc: 0.8839 - val_loss: 0.3478 - val_acc: 0.8466\n",
      "Epoch 10/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2790 - acc: 0.8861 - val_loss: 0.3250 - val_acc: 0.8513\n",
      "Epoch 11/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2734 - acc: 0.8899 - val_loss: 0.3251 - val_acc: 0.8514\n",
      "Epoch 12/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2704 - acc: 0.8918 - val_loss: 0.3342 - val_acc: 0.8469\n",
      "Epoch 13/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2658 - acc: 0.8930 - val_loss: 0.4018 - val_acc: 0.8364\n",
      "Epoch 14/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.2631 - acc: 0.8948 - val_loss: 0.3592 - val_acc: 0.8555\n",
      "Epoch 15/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.2586 - acc: 0.8965 - val_loss: 0.3222 - val_acc: 0.8552\n",
      "Epoch 16/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2571 - acc: 0.8976 - val_loss: 0.2706 - val_acc: 0.8764\n",
      "Epoch 17/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2529 - acc: 0.8994 - val_loss: 0.3666 - val_acc: 0.8446\n",
      "Epoch 18/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2506 - acc: 0.9009 - val_loss: 0.4061 - val_acc: 0.8433\n",
      "Epoch 19/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2487 - acc: 0.9022 - val_loss: 0.4018 - val_acc: 0.8493\n",
      "Epoch 20/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2452 - acc: 0.9024 - val_loss: 0.3809 - val_acc: 0.8502\n",
      "Epoch 21/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2441 - acc: 0.9033 - val_loss: 0.3153 - val_acc: 0.8639\n",
      "Epoch 22/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2423 - acc: 0.9045 - val_loss: 0.3282 - val_acc: 0.8467\n",
      "Epoch 23/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.2391 - acc: 0.9052 - val_loss: 0.3054 - val_acc: 0.8678\n",
      "Epoch 24/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.2384 - acc: 0.9053 - val_loss: 0.3333 - val_acc: 0.8562\n",
      "Epoch 25/10000\n",
      "97561/97561 [==============================] - 7s - loss: 0.2372 - acc: 0.9058 - val_loss: 0.3813 - val_acc: 0.8400\n",
      "Epoch 26/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2347 - acc: 0.9070 - val_loss: 0.3744 - val_acc: 0.8609\n",
      "Epoch 27/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2340 - acc: 0.9077 - val_loss: 0.4202 - val_acc: 0.8409\n",
      "Epoch 28/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2327 - acc: 0.9086 - val_loss: 0.2528 - val_acc: 0.8926\n",
      "Epoch 29/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2302 - acc: 0.9091 - val_loss: 0.3874 - val_acc: 0.8397\n",
      "Epoch 30/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2292 - acc: 0.9097 - val_loss: 0.3104 - val_acc: 0.8714\n",
      "Epoch 31/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2283 - acc: 0.9099 - val_loss: 0.2921 - val_acc: 0.8723\n",
      "Epoch 32/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2261 - acc: 0.9108 - val_loss: 0.3965 - val_acc: 0.8305\n",
      "Epoch 33/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2245 - acc: 0.9118 - val_loss: 0.2963 - val_acc: 0.8710\n",
      "Epoch 34/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2236 - acc: 0.9125 - val_loss: 0.3253 - val_acc: 0.8647\n",
      "Epoch 35/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2226 - acc: 0.9124 - val_loss: 0.3718 - val_acc: 0.8375\n",
      "Epoch 36/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2215 - acc: 0.9137 - val_loss: 0.3775 - val_acc: 0.8538\n",
      "Epoch 37/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2206 - acc: 0.9139 - val_loss: 0.3184 - val_acc: 0.8517\n",
      "Epoch 38/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2202 - acc: 0.9128 - val_loss: 0.2821 - val_acc: 0.8768\n",
      "Epoch 39/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2184 - acc: 0.9146 - val_loss: 0.3729 - val_acc: 0.8563\n",
      "Epoch 40/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2177 - acc: 0.9150 - val_loss: 0.4584 - val_acc: 0.8383\n",
      "Epoch 41/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2169 - acc: 0.9159 - val_loss: 0.3332 - val_acc: 0.8593\n",
      "Epoch 42/10000\n",
      "97561/97561 [==============================] - 6s - loss: 0.2158 - acc: 0.9160 - val_loss: 0.3603 - val_acc: 0.8619\n",
      "Epoch 43/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2164 - acc: 0.9156 - val_loss: 0.3239 - val_acc: 0.8518\n",
      "Epoch 44/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2139 - acc: 0.9170 - val_loss: 0.3358 - val_acc: 0.8580\n",
      "Epoch 45/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2133 - acc: 0.9170 - val_loss: 0.2660 - val_acc: 0.8877\n",
      "Epoch 46/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2138 - acc: 0.9167 - val_loss: 0.3936 - val_acc: 0.8530\n",
      "Epoch 47/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2126 - acc: 0.9174 - val_loss: 0.3067 - val_acc: 0.8713\n",
      "Epoch 48/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97561/97561 [==============================] - 5s - loss: 0.2113 - acc: 0.9178 - val_loss: 0.3602 - val_acc: 0.8568\n",
      "Epoch 49/10000\n",
      "97561/97561 [==============================] - 5s - loss: 0.2109 - acc: 0.9182 - val_loss: 0.3460 - val_acc: 0.8524\n",
      "97561/97561 [==============================] - 6s     \n",
      "KF_8\n",
      "Train on 97693 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.4547 - acc: 0.7964 - val_loss: 0.4755 - val_acc: 0.7582\n",
      "Epoch 2/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.3947 - acc: 0.8352 - val_loss: 0.4790 - val_acc: 0.7915\n",
      "Epoch 3/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.3615 - acc: 0.8510 - val_loss: 0.4303 - val_acc: 0.8154\n",
      "Epoch 4/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.3401 - acc: 0.8605 - val_loss: 0.3097 - val_acc: 0.8584\n",
      "Epoch 5/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.3228 - acc: 0.8675 - val_loss: 0.3606 - val_acc: 0.8549\n",
      "Epoch 6/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.3112 - acc: 0.8731 - val_loss: 0.3443 - val_acc: 0.8538\n",
      "Epoch 7/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.3036 - acc: 0.8759 - val_loss: 0.3823 - val_acc: 0.8303\n",
      "Epoch 8/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2951 - acc: 0.8800 - val_loss: 0.4251 - val_acc: 0.8307\n",
      "Epoch 9/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2880 - acc: 0.8829 - val_loss: 0.3380 - val_acc: 0.8563\n",
      "Epoch 10/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2835 - acc: 0.8848 - val_loss: 0.3313 - val_acc: 0.8542\n",
      "Epoch 11/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2770 - acc: 0.8878 - val_loss: 0.3851 - val_acc: 0.8435\n",
      "Epoch 12/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2733 - acc: 0.8891 - val_loss: 0.3325 - val_acc: 0.8484\n",
      "Epoch 13/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2694 - acc: 0.8912 - val_loss: 0.2640 - val_acc: 0.8796\n",
      "Epoch 14/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2670 - acc: 0.8922 - val_loss: 0.2868 - val_acc: 0.8653\n",
      "Epoch 15/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2631 - acc: 0.8937 - val_loss: 0.2993 - val_acc: 0.8678\n",
      "Epoch 16/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2598 - acc: 0.8962 - val_loss: 0.3245 - val_acc: 0.8574\n",
      "Epoch 17/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2574 - acc: 0.8967 - val_loss: 0.3680 - val_acc: 0.8504\n",
      "Epoch 18/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2553 - acc: 0.8977 - val_loss: 0.4129 - val_acc: 0.8321\n",
      "Epoch 19/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2532 - acc: 0.8980 - val_loss: 0.2669 - val_acc: 0.8803\n",
      "Epoch 20/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2511 - acc: 0.9001 - val_loss: 0.3494 - val_acc: 0.8557\n",
      "Epoch 21/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2479 - acc: 0.9014 - val_loss: 0.3377 - val_acc: 0.8585\n",
      "Epoch 22/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2474 - acc: 0.9018 - val_loss: 0.4345 - val_acc: 0.8313\n",
      "Epoch 23/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2450 - acc: 0.9030 - val_loss: 0.3691 - val_acc: 0.8471\n",
      "Epoch 24/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2425 - acc: 0.9043 - val_loss: 0.2590 - val_acc: 0.8868\n",
      "Epoch 25/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2409 - acc: 0.9053 - val_loss: 0.2552 - val_acc: 0.8860\n",
      "Epoch 26/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2392 - acc: 0.9058 - val_loss: 0.2622 - val_acc: 0.8824\n",
      "Epoch 27/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2379 - acc: 0.9069 - val_loss: 0.3491 - val_acc: 0.8590\n",
      "Epoch 28/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2361 - acc: 0.9076 - val_loss: 0.2196 - val_acc: 0.9152\n",
      "Epoch 29/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2357 - acc: 0.9083 - val_loss: 0.3390 - val_acc: 0.8597\n",
      "Epoch 30/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2337 - acc: 0.9088 - val_loss: 0.3350 - val_acc: 0.8599\n",
      "Epoch 31/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2315 - acc: 0.9095 - val_loss: 0.3168 - val_acc: 0.8612\n",
      "Epoch 32/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2307 - acc: 0.9100 - val_loss: 0.2779 - val_acc: 0.8746\n",
      "Epoch 33/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2290 - acc: 0.9109 - val_loss: 0.5221 - val_acc: 0.8153\n",
      "Epoch 34/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2290 - acc: 0.9104 - val_loss: 0.3516 - val_acc: 0.8562\n",
      "Epoch 35/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2272 - acc: 0.9114 - val_loss: 0.3018 - val_acc: 0.8685\n",
      "Epoch 36/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2258 - acc: 0.9123 - val_loss: 0.2732 - val_acc: 0.8822\n",
      "Epoch 37/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2245 - acc: 0.9138 - val_loss: 0.2917 - val_acc: 0.8810\n",
      "Epoch 38/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2240 - acc: 0.9132 - val_loss: 0.3746 - val_acc: 0.8536\n",
      "Epoch 39/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2232 - acc: 0.9142 - val_loss: 0.3136 - val_acc: 0.8627\n",
      "Epoch 40/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2203 - acc: 0.9147 - val_loss: 0.3586 - val_acc: 0.8579\n",
      "Epoch 41/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2206 - acc: 0.9152 - val_loss: 0.3472 - val_acc: 0.8625\n",
      "Epoch 42/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2194 - acc: 0.9151 - val_loss: 0.3585 - val_acc: 0.8582\n",
      "Epoch 43/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2194 - acc: 0.9151 - val_loss: 0.4332 - val_acc: 0.8446\n",
      "Epoch 44/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2175 - acc: 0.9164 - val_loss: 0.2978 - val_acc: 0.8735\n",
      "Epoch 45/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2168 - acc: 0.9170 - val_loss: 0.3273 - val_acc: 0.8661\n",
      "Epoch 46/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2153 - acc: 0.9166 - val_loss: 0.3098 - val_acc: 0.8679\n",
      "Epoch 47/10000\n",
      "97693/97693 [==============================] - 5s - loss: 0.2146 - acc: 0.9179 - val_loss: 0.2566 - val_acc: 0.8932\n",
      "Epoch 48/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2155 - acc: 0.9173 - val_loss: 0.3526 - val_acc: 0.8578\n",
      "Epoch 49/10000\n",
      "97693/97693 [==============================] - 6s - loss: 0.2134 - acc: 0.9188 - val_loss: 0.2875 - val_acc: 0.8792\n",
      "97312/97693 [============================>.] - ETA: 0sKF_9\n",
      "Train on 97659 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.4579 - acc: 0.8000 - val_loss: 0.5221 - val_acc: 0.7370\n",
      "Epoch 2/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.4007 - acc: 0.8337 - val_loss: 0.5415 - val_acc: 0.7442\n",
      "Epoch 3/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.3702 - acc: 0.8480 - val_loss: 0.4043 - val_acc: 0.8338\n",
      "Epoch 4/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.3506 - acc: 0.8551 - val_loss: 0.3807 - val_acc: 0.8441\n",
      "Epoch 5/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.3341 - acc: 0.8625 - val_loss: 0.3793 - val_acc: 0.8416\n",
      "Epoch 6/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.3236 - acc: 0.8669 - val_loss: 0.3903 - val_acc: 0.8443\n",
      "Epoch 7/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.3149 - acc: 0.8714 - val_loss: 0.3088 - val_acc: 0.8684\n",
      "Epoch 8/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.3068 - acc: 0.8750 - val_loss: 0.4794 - val_acc: 0.8160\n",
      "Epoch 9/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.3015 - acc: 0.8772 - val_loss: 0.3032 - val_acc: 0.8525\n",
      "Epoch 10/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2955 - acc: 0.8799 - val_loss: 0.4277 - val_acc: 0.8197\n",
      "Epoch 11/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97659/97659 [==============================] - 5s - loss: 0.2905 - acc: 0.8821 - val_loss: 0.3470 - val_acc: 0.8452\n",
      "Epoch 12/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2863 - acc: 0.8840 - val_loss: 0.3833 - val_acc: 0.8365\n",
      "Epoch 13/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2828 - acc: 0.8852 - val_loss: 0.4903 - val_acc: 0.8093\n",
      "Epoch 14/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2795 - acc: 0.8869 - val_loss: 0.3439 - val_acc: 0.8642\n",
      "Epoch 15/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2769 - acc: 0.8876 - val_loss: 0.2882 - val_acc: 0.8740\n",
      "Epoch 16/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2715 - acc: 0.8908 - val_loss: 0.8061 - val_acc: 0.7203\n",
      "Epoch 17/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2718 - acc: 0.8908 - val_loss: 0.4032 - val_acc: 0.8445\n",
      "Epoch 18/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2662 - acc: 0.8924 - val_loss: 0.2265 - val_acc: 0.9166\n",
      "Epoch 19/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2654 - acc: 0.8927 - val_loss: 0.4143 - val_acc: 0.8514\n",
      "Epoch 20/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2632 - acc: 0.8934 - val_loss: 0.3302 - val_acc: 0.8643\n",
      "Epoch 21/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2589 - acc: 0.8951 - val_loss: 0.4240 - val_acc: 0.8403\n",
      "Epoch 22/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2577 - acc: 0.8957 - val_loss: 0.4350 - val_acc: 0.8514\n",
      "Epoch 23/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2550 - acc: 0.8978 - val_loss: 0.4121 - val_acc: 0.8546\n",
      "Epoch 24/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2557 - acc: 0.8977 - val_loss: 0.2374 - val_acc: 0.8948\n",
      "Epoch 25/10000\n",
      "97659/97659 [==============================] - 5s - loss: 0.2516 - acc: 0.8986 - val_loss: 0.2189 - val_acc: 0.9239\n",
      "Epoch 26/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2495 - acc: 0.8999 - val_loss: 0.4397 - val_acc: 0.8416\n",
      "Epoch 27/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2476 - acc: 0.9008 - val_loss: 0.2200 - val_acc: 0.9099\n",
      "Epoch 28/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2464 - acc: 0.9013 - val_loss: 0.5035 - val_acc: 0.8161\n",
      "Epoch 29/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2455 - acc: 0.9020 - val_loss: 0.2483 - val_acc: 0.8937\n",
      "Epoch 30/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2437 - acc: 0.9022 - val_loss: 0.2226 - val_acc: 0.9162\n",
      "Epoch 31/10000\n",
      "97659/97659 [==============================] - 7s - loss: 0.2426 - acc: 0.9026 - val_loss: 0.2906 - val_acc: 0.8766\n",
      "Epoch 32/10000\n",
      "97659/97659 [==============================] - 7s - loss: 0.2392 - acc: 0.9040 - val_loss: 0.3085 - val_acc: 0.8713\n",
      "Epoch 33/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2387 - acc: 0.9045 - val_loss: 0.4027 - val_acc: 0.8251\n",
      "Epoch 34/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2378 - acc: 0.9051 - val_loss: 0.4939 - val_acc: 0.7991\n",
      "Epoch 35/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2369 - acc: 0.9055 - val_loss: 0.2713 - val_acc: 0.8929\n",
      "Epoch 36/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2359 - acc: 0.9054 - val_loss: 0.2848 - val_acc: 0.8761\n",
      "Epoch 37/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2343 - acc: 0.9066 - val_loss: 0.3328 - val_acc: 0.8705\n",
      "Epoch 38/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2356 - acc: 0.9056 - val_loss: 0.2923 - val_acc: 0.8782\n",
      "Epoch 39/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2334 - acc: 0.9066 - val_loss: 0.6007 - val_acc: 0.7831\n",
      "Epoch 40/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2324 - acc: 0.9079 - val_loss: 0.3469 - val_acc: 0.8507\n",
      "Epoch 41/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2299 - acc: 0.9082 - val_loss: 0.3798 - val_acc: 0.8620\n",
      "Epoch 42/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2286 - acc: 0.9091 - val_loss: 0.2710 - val_acc: 0.8904\n",
      "Epoch 43/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2301 - acc: 0.9081 - val_loss: 0.2130 - val_acc: 0.9282\n",
      "Epoch 44/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2278 - acc: 0.9091 - val_loss: 0.2421 - val_acc: 0.9030\n",
      "Epoch 45/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2276 - acc: 0.9096 - val_loss: 0.2272 - val_acc: 0.9186\n",
      "Epoch 46/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2268 - acc: 0.9094 - val_loss: 0.2904 - val_acc: 0.8728\n",
      "Epoch 47/10000\n",
      "97659/97659 [==============================] - 7s - loss: 0.2253 - acc: 0.9108 - val_loss: 0.4956 - val_acc: 0.8057\n",
      "Epoch 48/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2252 - acc: 0.9111 - val_loss: 0.3670 - val_acc: 0.8568\n",
      "Epoch 49/10000\n",
      "97659/97659 [==============================] - 7s - loss: 0.2239 - acc: 0.9118 - val_loss: 0.6655 - val_acc: 0.7835\n",
      "Epoch 50/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2241 - acc: 0.9118 - val_loss: 0.3056 - val_acc: 0.8616\n",
      "Epoch 51/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2231 - acc: 0.9110 - val_loss: 0.3714 - val_acc: 0.8639\n",
      "Epoch 52/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2213 - acc: 0.9126 - val_loss: 0.3865 - val_acc: 0.8557\n",
      "Epoch 53/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2209 - acc: 0.9121 - val_loss: 0.3714 - val_acc: 0.8625\n",
      "Epoch 54/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2207 - acc: 0.9120 - val_loss: 0.3271 - val_acc: 0.8727\n",
      "Epoch 55/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2191 - acc: 0.9125 - val_loss: 0.3133 - val_acc: 0.8720\n",
      "Epoch 56/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2185 - acc: 0.9138 - val_loss: 0.4111 - val_acc: 0.8484\n",
      "Epoch 57/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2193 - acc: 0.9134 - val_loss: 0.3118 - val_acc: 0.8772\n",
      "Epoch 58/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2187 - acc: 0.9135 - val_loss: 0.2589 - val_acc: 0.8967\n",
      "Epoch 59/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2178 - acc: 0.9144 - val_loss: 0.4483 - val_acc: 0.8246\n",
      "Epoch 60/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2180 - acc: 0.9137 - val_loss: 0.5109 - val_acc: 0.8047\n",
      "Epoch 61/10000\n",
      "97659/97659 [==============================] - 7s - loss: 0.2165 - acc: 0.9147 - val_loss: 0.3397 - val_acc: 0.8350\n",
      "Epoch 62/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2152 - acc: 0.9151 - val_loss: 0.2698 - val_acc: 0.8906\n",
      "Epoch 63/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2155 - acc: 0.9143 - val_loss: 0.3858 - val_acc: 0.8603\n",
      "Epoch 64/10000\n",
      "97659/97659 [==============================] - 6s - loss: 0.2149 - acc: 0.9149 - val_loss: 0.2837 - val_acc: 0.8867\n",
      "97312/97659 [============================>.] - ETA: 0sKF_10\n",
      "Train on 97544 samples, validate on 13684 samples\n",
      "Epoch 1/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.4619 - acc: 0.7929 - val_loss: 0.4336 - val_acc: 0.8013\n",
      "Epoch 2/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.3966 - acc: 0.8344 - val_loss: 0.4465 - val_acc: 0.8066\n",
      "Epoch 3/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.3623 - acc: 0.8491 - val_loss: 0.3959 - val_acc: 0.8362\n",
      "Epoch 4/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.3377 - acc: 0.8606 - val_loss: 0.4616 - val_acc: 0.8278\n",
      "Epoch 5/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.3214 - acc: 0.8665 - val_loss: 0.3417 - val_acc: 0.8381\n",
      "Epoch 6/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.3094 - acc: 0.8725 - val_loss: 0.3803 - val_acc: 0.8396\n",
      "Epoch 7/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.3000 - acc: 0.8768 - val_loss: 0.3841 - val_acc: 0.8292\n",
      "Epoch 8/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97544/97544 [==============================] - 6s - loss: 0.2939 - acc: 0.8796 - val_loss: 0.4167 - val_acc: 0.8355\n",
      "Epoch 9/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2870 - acc: 0.8835 - val_loss: 0.2954 - val_acc: 0.8522\n",
      "Epoch 10/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2830 - acc: 0.8851 - val_loss: 0.3907 - val_acc: 0.8473\n",
      "Epoch 11/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.2772 - acc: 0.8871 - val_loss: 0.2669 - val_acc: 0.8737\n",
      "Epoch 12/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2727 - acc: 0.8890 - val_loss: 0.3665 - val_acc: 0.8435\n",
      "Epoch 13/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2684 - acc: 0.8918 - val_loss: 0.3118 - val_acc: 0.8593\n",
      "Epoch 14/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2648 - acc: 0.8926 - val_loss: 0.3443 - val_acc: 0.8574\n",
      "Epoch 15/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2626 - acc: 0.8943 - val_loss: 0.3027 - val_acc: 0.8685\n",
      "Epoch 16/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2587 - acc: 0.8953 - val_loss: 0.4080 - val_acc: 0.8269\n",
      "Epoch 17/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2574 - acc: 0.8962 - val_loss: 0.3058 - val_acc: 0.8679\n",
      "Epoch 18/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2554 - acc: 0.8972 - val_loss: 0.4099 - val_acc: 0.8336\n",
      "Epoch 19/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2528 - acc: 0.8983 - val_loss: 0.3744 - val_acc: 0.8514\n",
      "Epoch 20/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2494 - acc: 0.8992 - val_loss: 0.2935 - val_acc: 0.8709\n",
      "Epoch 21/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.2487 - acc: 0.8990 - val_loss: 0.2704 - val_acc: 0.8827\n",
      "Epoch 22/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.2464 - acc: 0.9015 - val_loss: 0.2995 - val_acc: 0.8650\n",
      "Epoch 23/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2441 - acc: 0.9018 - val_loss: 0.4164 - val_acc: 0.8356\n",
      "Epoch 24/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2435 - acc: 0.9021 - val_loss: 0.3588 - val_acc: 0.8537\n",
      "Epoch 25/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2408 - acc: 0.9033 - val_loss: 0.3072 - val_acc: 0.8630\n",
      "Epoch 26/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2403 - acc: 0.9035 - val_loss: 0.3365 - val_acc: 0.8603\n",
      "Epoch 27/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2385 - acc: 0.9051 - val_loss: 0.4077 - val_acc: 0.8491\n",
      "Epoch 28/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2364 - acc: 0.9055 - val_loss: 0.3211 - val_acc: 0.8654\n",
      "Epoch 29/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2350 - acc: 0.9054 - val_loss: 0.3010 - val_acc: 0.8704\n",
      "Epoch 30/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2359 - acc: 0.9062 - val_loss: 0.3110 - val_acc: 0.8686\n",
      "Epoch 31/10000\n",
      "97544/97544 [==============================] - 6s - loss: 0.2328 - acc: 0.9072 - val_loss: 0.3459 - val_acc: 0.8565\n",
      "Epoch 32/10000\n",
      "97544/97544 [==============================] - 5s - loss: 0.2321 - acc: 0.9074 - val_loss: 0.2811 - val_acc: 0.8756\n",
      "97344/97544 [============================>.] - ETA: 0s\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "model_name = 'MLP'\n",
    "\n",
    "i = 1\n",
    "metrics_kf = pd.DataFrame()\n",
    "for train, test in kfold.split(x_data, y_data):\n",
    "\n",
    "    ## Data\n",
    "    x_train = x_data.iloc[train]\n",
    "    y_train = y_data.iloc[train]\n",
    "    \n",
    "    x_test = x_data.iloc[test]\n",
    "    y_test = y_data.iloc[test]\n",
    "    \n",
    "    ## Train, validation\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train)\n",
    "    \n",
    "    ## Remove duplicate label (Train)\n",
    "    removeIndex = x_train[x_train.duplicated(keep=False)].index\n",
    "    x_train = x_train.drop(removeIndex)\n",
    "    y_train = y_train.drop(removeIndex)\n",
    "    \n",
    "    ## Standard Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    \n",
    "    # Oversampling\n",
    "    sampling = SMOTE(kind='borderline2',k_neighbors=5, random_state=42, n_jobs=4)\n",
    "    x_train, y_train = sampling.fit_sample(x_train, y_train)\n",
    "    \n",
    "    # one hot\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_val = to_categorical(y_val)\n",
    "    \n",
    "    ## status\n",
    "    kf_i = 'KF_{0}'.format(i)\n",
    "    print(kf_i)\n",
    "    \n",
    "    ## Train\n",
    "    startTime = time.time()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, activation='tanh', input_dim=x_train.shape[1]))\n",
    "    model.add(Dense(80, activation='tanh'))\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train,y_train,\n",
    "                  batch_size=150,\n",
    "                  epochs=10000,\n",
    "                  callbacks=[EarlyStopping(patience=20)],\n",
    "                  validation_data=(x_val, y_val))\n",
    "    tm = timedelta(seconds=(time.time()-startTime))\n",
    "    \n",
    "    ## Predict\n",
    "    y_pred_proba = model.predict_proba(x_test)\n",
    "    y_pred = y_pred_proba.argmax(axis=1)\n",
    "    \n",
    "    ## Metrics\n",
    "    auc_train = roc_auc_score(y_train[:,1], model.predict_proba(x_train)[:,1])\n",
    "    fpr, tpr, thresholds = roc_curve(y_test.values, y_pred_proba[:,1])\n",
    "    auc_1 = auc(fpr, tpr)\n",
    "    auc_0 = auc(1-tpr, 1-fpr)\n",
    "    precision = precision_score(y_test.values, y_pred, average='macro')\n",
    "    recall = recall_score(y_test.values, y_pred, average='macro')  \n",
    "    f1 = f1_score(y_test.values, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test.values, y_pred)\n",
    "           \n",
    "    metrics_kf.loc[kf_i,'AURoc Train'] = auc_train\n",
    "    metrics_kf.loc[kf_i,'AURoc 0'] = auc_0\n",
    "    metrics_kf.loc[kf_i,'AURoc 1'] = auc_1\n",
    "    metrics_kf.loc[kf_i,'Precision'] = precision\n",
    "    metrics_kf.loc[kf_i,'Recall'] = recall\n",
    "    metrics_kf.loc[kf_i,'F1 score'] = f1\n",
    "    metrics_kf.loc[kf_i,'Accuracy'] = accuracy\n",
    "    metrics_kf.loc[kf_i,'Time'] = tm\n",
    "    i=i+1\n",
    "    clear_session()\n",
    "\n",
    "print()\n",
    "for m in ['AURoc Train', 'AURoc 0', 'AURoc 1', 'Precision', 'Recall', 'F1 score', 'Accuracy', 'Time']:\n",
    "\n",
    "    mean = metrics_kf[m].mean()\n",
    "    metrics_kf.loc['Media', m] = mean\n",
    "    models.loc[model_name, m] = mean\n",
    "    \n",
    "    metrics_kf.loc['STD', m] = metrics_kf[m].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AURoc Train</th>\n",
       "      <th>AURoc 0</th>\n",
       "      <th>AURoc 1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KF_1</th>\n",
       "      <td>0.970911</td>\n",
       "      <td>0.757198</td>\n",
       "      <td>0.757198</td>\n",
       "      <td>0.558525</td>\n",
       "      <td>0.682628</td>\n",
       "      <td>0.571142</td>\n",
       "      <td>0.861502</td>\n",
       "      <td>00:04:56.887894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_2</th>\n",
       "      <td>0.967114</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.559256</td>\n",
       "      <td>0.707993</td>\n",
       "      <td>0.568739</td>\n",
       "      <td>0.845982</td>\n",
       "      <td>00:03:52.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_3</th>\n",
       "      <td>0.968360</td>\n",
       "      <td>0.765806</td>\n",
       "      <td>0.765806</td>\n",
       "      <td>0.554116</td>\n",
       "      <td>0.702728</td>\n",
       "      <td>0.558289</td>\n",
       "      <td>0.832807</td>\n",
       "      <td>00:04:08.726121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_4</th>\n",
       "      <td>0.974384</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.568099</td>\n",
       "      <td>0.712160</td>\n",
       "      <td>0.585242</td>\n",
       "      <td>0.866219</td>\n",
       "      <td>00:05:48.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_5</th>\n",
       "      <td>0.968261</td>\n",
       "      <td>0.766914</td>\n",
       "      <td>0.766914</td>\n",
       "      <td>0.553092</td>\n",
       "      <td>0.699132</td>\n",
       "      <td>0.556690</td>\n",
       "      <td>0.832018</td>\n",
       "      <td>00:04:13.079238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_6</th>\n",
       "      <td>0.968878</td>\n",
       "      <td>0.790803</td>\n",
       "      <td>0.790803</td>\n",
       "      <td>0.563131</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.574108</td>\n",
       "      <td>0.846356</td>\n",
       "      <td>00:03:29.194491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_7</th>\n",
       "      <td>0.973293</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>0.715620</td>\n",
       "      <td>0.577371</td>\n",
       "      <td>0.854512</td>\n",
       "      <td>00:05:08.958031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_8</th>\n",
       "      <td>0.972240</td>\n",
       "      <td>0.759889</td>\n",
       "      <td>0.759889</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>0.682309</td>\n",
       "      <td>0.584724</td>\n",
       "      <td>0.879242</td>\n",
       "      <td>00:04:50.704065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_9</th>\n",
       "      <td>0.971913</td>\n",
       "      <td>0.774563</td>\n",
       "      <td>0.774563</td>\n",
       "      <td>0.569239</td>\n",
       "      <td>0.683820</td>\n",
       "      <td>0.588930</td>\n",
       "      <td>0.883831</td>\n",
       "      <td>00:06:37.341898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KF_10</th>\n",
       "      <td>0.966630</td>\n",
       "      <td>0.736981</td>\n",
       "      <td>0.740314</td>\n",
       "      <td>0.559593</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>0.574771</td>\n",
       "      <td>0.875674</td>\n",
       "      <td>00:03:13.684673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media</th>\n",
       "      <td>0.970198</td>\n",
       "      <td>0.765311</td>\n",
       "      <td>0.765644</td>\n",
       "      <td>0.561563</td>\n",
       "      <td>0.697569</td>\n",
       "      <td>0.574001</td>\n",
       "      <td>0.857814</td>\n",
       "      <td>00:04:37.896317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STD</th>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.013211</td>\n",
       "      <td>0.012516</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.017535</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>00:01:00.019495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AURoc Train   AURoc 0   AURoc 1  Precision    Recall  F1 score  \\\n",
       "KF_1      0.970911  0.757198  0.757198   0.558525  0.682628  0.571142   \n",
       "KF_2      0.967114  0.759036  0.759036   0.559256  0.707993  0.568739   \n",
       "KF_3      0.968360  0.765806  0.765806   0.554116  0.702728  0.558289   \n",
       "KF_4      0.974384  0.769231  0.769231   0.568099  0.712160  0.585242   \n",
       "KF_5      0.968261  0.766914  0.766914   0.553092  0.699132  0.556690   \n",
       "KF_6      0.968878  0.790803  0.790803   0.563131  0.724116  0.574108   \n",
       "KF_7      0.973293  0.772686  0.772686   0.564092  0.715620  0.577371   \n",
       "KF_8      0.972240  0.759889  0.759889   0.566486  0.682309  0.584724   \n",
       "KF_9      0.971913  0.774563  0.774563   0.569239  0.683820  0.588930   \n",
       "KF_10     0.966630  0.736981  0.740314   0.559593  0.665190  0.574771   \n",
       "Media     0.970198  0.765311  0.765644   0.561563  0.697569  0.574001   \n",
       "STD       0.002566  0.013211  0.012516   0.005295  0.017535  0.010289   \n",
       "\n",
       "       Accuracy            Time  \n",
       "KF_1   0.861502 00:04:56.887894  \n",
       "KF_2   0.845982 00:03:52.375400  \n",
       "KF_3   0.832807 00:04:08.726121  \n",
       "KF_4   0.866219 00:05:48.011362  \n",
       "KF_5   0.832018 00:04:13.079238  \n",
       "KF_6   0.846356 00:03:29.194491  \n",
       "KF_7   0.854512 00:05:08.958031  \n",
       "KF_8   0.879242 00:04:50.704065  \n",
       "KF_9   0.883831 00:06:37.341898  \n",
       "KF_10  0.875674 00:03:13.684673  \n",
       "Media  0.857814 00:04:37.896317  \n",
       "STD    0.017642 00:01:00.019495  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_name)\n",
    "\n",
    "metrics_kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('K-Fold: 10')\n",
    "\n",
    "models.sort_values(['F1 score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
